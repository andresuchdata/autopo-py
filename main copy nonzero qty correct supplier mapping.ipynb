{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26400c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e807c25",
   "metadata": {},
   "source": [
    "# Convert xlsx to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dbe537c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['28. Miss Glam Aceh.xlsx',\n",
       " '20. Miss Glam Tanjung Pinang.xlsx',\n",
       " '7.Miss glam Lampung.xlsx',\n",
       " '1.Miss glam Padang.xlsx',\n",
       " '30. Miss Glam Sei Penuh.xlsx',\n",
       " '21. Miss Glam Sutomo.xlsx',\n",
       " '15.Miss glam Tembilahan.xlsx',\n",
       " '.DS_Store',\n",
       " '14.Miss glam Solok.xlsx',\n",
       " '27. Miss Glam Padang Sidimpuan.xlsx',\n",
       " '17.Miss glam Dumai.xlsx',\n",
       " '12.Miss glam Bangka.xlsx',\n",
       " '10.Miss glam Palembang.xlsx',\n",
       " '8.Miss glam Bengkulu.xlsx',\n",
       " '11.Miss glam Damar.xlsx',\n",
       " '33. Miss Glam Balikpapan.xlsx',\n",
       " '23. Miss Glam Halat.xlsx',\n",
       " '19. Miss Glam Rantau Prapat.xlsx',\n",
       " '18. Miss Glam Kedaton.xlsx',\n",
       " '6.Miss glam Muaro bungo.xlsx',\n",
       " '16.Miss glam Lubuk Linggau.xlsx',\n",
       " '25. Miss Glam Sudirman.xlsx',\n",
       " '3.Miss glam Jambi.xlsx',\n",
       " '31. Miss Glam Mayang.xlsx',\n",
       " '13.Miss glam Payakumbuh.xlsx',\n",
       " '4.Miss glam Bukittinggi.xlsx',\n",
       " '26. Miss Glam dr Mansur .xlsx',\n",
       " '22. Miss Glam Pasaman Barat.xlsx',\n",
       " '32. Miss Glam Soeta.xlsx',\n",
       " '2.Miss glam Pekanbaru.xlsx',\n",
       " '24. Miss Glam Duri.xlsx',\n",
       " '9.Miss glam Medan.xlsx',\n",
       " '5.Miss glam Panam.xlsx',\n",
       " '29. Miss Glam Marpoyan.xlsx']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 33 .xlsx files to process...\n",
      "\n",
      "===========================================Converting 28. Miss Glam Aceh.xlsx to 28. Miss Glam Aceh.csv...\n",
      "Error processing 28. Miss Glam Aceh.xlsx: invalid literal for int() with base 10: 'NAN'\n",
      "\n",
      "===========================================Converting 20. Miss Glam Tanjung Pinang.xlsx to 20. Miss Glam Tanjung Pinang.csv...\n",
      "Error processing 20. Miss Glam Tanjung Pinang.xlsx: invalid literal for int() with base 10: 'NAN'\n",
      "\n",
      "===========================================Converting 7.Miss glam Lampung.xlsx to 7.Miss glam Lampung.csv...\n",
      "Error processing 7.Miss glam Lampung.xlsx: invalid literal for int() with base 10: 'INF'\n",
      "\n",
      "===========================================Converting 1.Miss glam Padang.xlsx to 1.Miss glam Padang.csv...\n",
      "Error processing 1.Miss glam Padang.xlsx: invalid literal for int() with base 10: 'NAN'\n",
      "\n",
      "===========================================Converting 30. Miss Glam Sei Penuh.xlsx to 30. Miss Glam Sei Penuh.csv...\n",
      "Error processing 30. Miss Glam Sei Penuh.xlsx: invalid literal for int() with base 10: 'NAN'\n",
      "\n",
      "===========================================Converting 21. Miss Glam Sutomo.xlsx to 21. Miss Glam Sutomo.csv...\n",
      "Error processing 21. Miss Glam Sutomo.xlsx: invalid literal for int() with base 10: 'NAN'\n",
      "\n",
      "===========================================Converting 15.Miss glam Tembilahan.xlsx to 15.Miss glam Tembilahan.csv...\n",
      "Error processing 15.Miss glam Tembilahan.xlsx: invalid literal for int() with base 10: 'INF'\n",
      "\n",
      "===========================================Converting 14.Miss glam Solok.xlsx to 14.Miss glam Solok.csv...\n",
      "Error processing 14.Miss glam Solok.xlsx: invalid literal for int() with base 10: 'NAN'\n",
      "\n",
      "===========================================Converting 27. Miss Glam Padang Sidimpuan.xlsx to 27. Miss Glam Padang Sidimpuan.csv...\n",
      "Error processing 27. Miss Glam Padang Sidimpuan.xlsx: invalid literal for int() with base 10: 'NAN'\n",
      "\n",
      "===========================================Converting 17.Miss glam Dumai.xlsx to 17.Miss glam Dumai.csv...\n",
      "Error processing 17.Miss glam Dumai.xlsx: invalid literal for int() with base 10: 'NAN'\n",
      "\n",
      "===========================================Converting 12.Miss glam Bangka.xlsx to 12.Miss glam Bangka.csv...\n",
      "Error processing 12.Miss glam Bangka.xlsx: invalid literal for int() with base 10: 'NAN'\n",
      "\n",
      "===========================================Converting 10.Miss glam Palembang.xlsx to 10.Miss glam Palembang.csv...\n",
      "Error processing 10.Miss glam Palembang.xlsx: invalid literal for int() with base 10: 'INF'\n",
      "\n",
      "===========================================Converting 8.Miss glam Bengkulu.xlsx to 8.Miss glam Bengkulu.csv...\n",
      "Error processing 8.Miss glam Bengkulu.xlsx: invalid literal for int() with base 10: 'NAN'\n",
      "\n",
      "===========================================Converting 11.Miss glam Damar.xlsx to 11.Miss glam Damar.csv...\n",
      "Error processing 11.Miss glam Damar.xlsx: invalid literal for int() with base 10: 'NAN'\n",
      "\n",
      "===========================================Converting 33. Miss Glam Balikpapan.xlsx to 33. Miss Glam Balikpapan.csv...\n",
      "Error processing 33. Miss Glam Balikpapan.xlsx: invalid literal for int() with base 10: 'NAN'\n",
      "\n",
      "===========================================Converting 23. Miss Glam Halat.xlsx to 23. Miss Glam Halat.csv...\n",
      "Error processing 23. Miss Glam Halat.xlsx: invalid literal for int() with base 10: 'NAN'\n",
      "\n",
      "===========================================Converting 19. Miss Glam Rantau Prapat.xlsx to 19. Miss Glam Rantau Prapat.csv...\n",
      "Error processing 19. Miss Glam Rantau Prapat.xlsx: invalid literal for int() with base 10: 'NAN'\n",
      "\n",
      "===========================================Converting 18. Miss Glam Kedaton.xlsx to 18. Miss Glam Kedaton.csv...\n",
      "Error processing 18. Miss Glam Kedaton.xlsx: invalid literal for int() with base 10: 'NAN'\n",
      "\n",
      "===========================================Converting 6.Miss glam Muaro bungo.xlsx to 6.Miss glam Muaro bungo.csv...\n",
      "Error processing 6.Miss glam Muaro bungo.xlsx: invalid literal for int() with base 10: 'NAN'\n",
      "\n",
      "===========================================Converting 16.Miss glam Lubuk Linggau.xlsx to 16.Miss glam Lubuk Linggau.csv...\n",
      "Error processing 16.Miss glam Lubuk Linggau.xlsx: invalid literal for int() with base 10: 'NAN'\n",
      "\n",
      "===========================================Converting 25. Miss Glam Sudirman.xlsx to 25. Miss Glam Sudirman.csv...\n",
      "Error processing 25. Miss Glam Sudirman.xlsx: invalid literal for int() with base 10: 'NAN'\n",
      "\n",
      "===========================================Converting 3.Miss glam Jambi.xlsx to 3.Miss glam Jambi.csv...\n",
      "Error processing 3.Miss glam Jambi.xlsx: invalid literal for int() with base 10: 'INF'\n",
      "\n",
      "===========================================Converting 31. Miss Glam Mayang.xlsx to 31. Miss Glam Mayang.csv...\n",
      "Error processing 31. Miss Glam Mayang.xlsx: invalid literal for int() with base 10: 'NAN'\n",
      "\n",
      "===========================================Converting 13.Miss glam Payakumbuh.xlsx to 13.Miss glam Payakumbuh.csv...\n",
      "Error processing 13.Miss glam Payakumbuh.xlsx: invalid literal for int() with base 10: 'NAN'\n",
      "\n",
      "===========================================Converting 4.Miss glam Bukittinggi.xlsx to 4.Miss glam Bukittinggi.csv...\n",
      "Error processing 4.Miss glam Bukittinggi.xlsx: invalid literal for int() with base 10: 'NAN'\n",
      "\n",
      "===========================================Converting 26. Miss Glam dr Mansur .xlsx to 26. Miss Glam dr Mansur .csv...\n",
      "Error processing 26. Miss Glam dr Mansur .xlsx: invalid literal for int() with base 10: 'NAN'\n",
      "\n",
      "===========================================Converting 22. Miss Glam Pasaman Barat.xlsx to 22. Miss Glam Pasaman Barat.csv...\n",
      "Error processing 22. Miss Glam Pasaman Barat.xlsx: invalid literal for int() with base 10: 'NAN'\n",
      "\n",
      "===========================================Converting 32. Miss Glam Soeta.xlsx to 32. Miss Glam Soeta.csv...\n",
      "Error processing 32. Miss Glam Soeta.xlsx: invalid literal for int() with base 10: 'NAN'\n",
      "\n",
      "===========================================Converting 2.Miss glam Pekanbaru.xlsx to 2.Miss glam Pekanbaru.csv...\n",
      "Error processing 2.Miss glam Pekanbaru.xlsx: invalid literal for int() with base 10: 'NAN'\n",
      "\n",
      "===========================================Converting 24. Miss Glam Duri.xlsx to 24. Miss Glam Duri.csv...\n",
      "Error processing 24. Miss Glam Duri.xlsx: invalid literal for int() with base 10: 'NAN'\n",
      "\n",
      "===========================================Converting 9.Miss glam Medan.xlsx to 9.Miss glam Medan.csv...\n",
      "Error processing 9.Miss glam Medan.xlsx: invalid literal for int() with base 10: 'NAN'\n",
      "\n",
      "===========================================Converting 5.Miss glam Panam.xlsx to 5.Miss glam Panam.csv...\n",
      "Error processing 5.Miss glam Panam.xlsx: invalid literal for int() with base 10: 'NAN'\n",
      "\n",
      "===========================================Converting 29. Miss Glam Marpoyan.xlsx to 29. Miss Glam Marpoyan.csv...\n",
      "Error processing 29. Miss Glam Marpoyan.xlsx: invalid literal for int() with base 10: 'NAN'\n",
      "Conversion complete!\n"
     ]
    }
   ],
   "source": [
    "raw_files = os.listdir('data/rawpo/xlsx')\n",
    "display(raw_files)\n",
    "\n",
    "CSV_OUTPUT_DIR = 'data/rawpo/csv_output'\n",
    "\n",
    "def convert_xlsx_to_csv(directory):\n",
    "    \"\"\"\n",
    "    Convert all .xlsx files in the specified directory to .csv format.\n",
    "    Skips files that already have a corresponding .csv file.\n",
    "    \n",
    "    Args:\n",
    "        directory (str): Path to the directory containing .xlsx files\n",
    "    \"\"\"\n",
    "    # Convert to Path object for easier handling\n",
    "    dir_path = Path(directory)\n",
    "    \n",
    "    # Find all .xlsx files in the directory\n",
    "    xlsx_files = list(dir_path.glob('*.xlsx'))\n",
    "    \n",
    "    if not xlsx_files:\n",
    "        print(f\"No .xlsx files found in {directory}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(xlsx_files)} .xlsx files to process...\")\n",
    "    \n",
    "    for xlsx_file in xlsx_files:\n",
    "        # Create output filename with .csv extension\n",
    "        csv_file = xlsx_file.with_suffix('.csv')\n",
    "        \n",
    "        # Skip if CSV already exists\n",
    "        if csv_file.exists():\n",
    "            print(f\"Skipping {xlsx_file.name} - {csv_file.name} already exists\")\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            # Read the Excel file\n",
    "            print(f\"\\n===========================================Converting {xlsx_file.name} to {csv_file.name}...\")\n",
    "            df = pd.read_excel(xlsx_file)\n",
    "            \n",
    "            # Write to CSV\n",
    "            df.to_csv(CSV_OUTPUT_DIR + csv_file.name, index=False, encoding='utf-8')\n",
    "            print(f\"Successfully created {csv_file.name}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {xlsx_file.name}: {str(e)}\")\n",
    "    \n",
    "    print(\"Conversion complete!\")\n",
    "\n",
    "# Example usage:\n",
    "convert_xlsx_to_csv('data/rawpo/xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "97300143",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/rawpo/01 Miss Glam Padang.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[274]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Read the Excel file, converting 'INF' to numpy.inf\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m ori_df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdata/rawpo/01 Miss Glam Padang.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m;\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m,\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Convert all numeric columns, handling infinity and NaN values\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m ori_df.select_dtypes(include=[np.number]).columns:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/missglam/.venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/missglam/.venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/missglam/.venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/missglam/.venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/missglam/.venv/lib/python3.13/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'data/rawpo/01 Miss Glam Padang.csv'"
     ]
    }
   ],
   "source": [
    "# Read the Excel file, converting 'INF' to numpy.inf\n",
    "ori_df = pd.read_csv('data/rawpo/01 Miss Glam Padang.csv', sep=';', decimal=',')\n",
    "\n",
    "# Convert all numeric columns, handling infinity and NaN values\n",
    "for col in ori_df.select_dtypes(include=[np.number]).columns:\n",
    "    ori_df[col] = pd.to_numeric(ori_df[col], errors='coerce')\n",
    "\n",
    "df = ori_df.copy()\n",
    "df = df.rename(columns={'Stok': 'Stock'})\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# extract only the columns we need\n",
    "display(df.info())\n",
    "df = df[['Brand', 'SKU', 'Nama', 'Stock', 'Daily Sales', 'Max. Daily Sales', 'Lead Time', 'Max. Lead Time', 'Sedang PO', 'Min. Order', 'HPP']]\n",
    "\n",
    "display(df)\n",
    "\n",
    "# contribution dictionary for each store location\n",
    "contribution_dict = {\n",
    "    'payakumbuh': 0.47,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "449d680d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/supplier.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[260]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# supplier mapping\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# to map an SKU and brand to specific supplier\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m raw_supplier_df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdata/supplier.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m;\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m,\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m raw_supplier_df = raw_supplier_df.fillna(\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      7\u001b[39m display(raw_supplier_df)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/missglam/.venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/missglam/.venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/missglam/.venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/missglam/.venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/missglam/.venv/lib/python3.13/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'data/supplier.csv'"
     ]
    }
   ],
   "source": [
    "# supplier mapping\n",
    "# to map an SKU and brand to specific supplier\n",
    "\n",
    "raw_supplier_df = pd.read_csv('data/supplier.csv', sep=';', decimal=',')\n",
    "raw_supplier_df = raw_supplier_df.fillna('')\n",
    "\n",
    "display(raw_supplier_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f860f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Raw DataFrame: '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>SKU</th>\n",
       "      <th>Nama</th>\n",
       "      <th>Stock</th>\n",
       "      <th>Daily Sales</th>\n",
       "      <th>Max. Daily Sales</th>\n",
       "      <th>Lead Time</th>\n",
       "      <th>Max. Lead Time</th>\n",
       "      <th>Sedang PO</th>\n",
       "      <th>Min. Order</th>\n",
       "      <th>HPP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACNAWAY</td>\n",
       "      <td>10400614911</td>\n",
       "      <td>ACNAWAY 3 in 1 Acne Sun Serum Sunscreen Serum ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>57850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACNAWAY</td>\n",
       "      <td>10100824612</td>\n",
       "      <td>ACNAWAY Mugwort Acne Clear Bar Soap 100gr</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>31000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACNAWAY</td>\n",
       "      <td>10400517459</td>\n",
       "      <td>ACNAWAY Mugwort Daily Sunscreen Only For Acne ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACNAWAY</td>\n",
       "      <td>101001107647</td>\n",
       "      <td>ACNAWAY Mugwort Gel Facial Wash Mugwort + Cent...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.80</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>31930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACNAWAY</td>\n",
       "      <td>10500637717</td>\n",
       "      <td>ACNAWAY Mugwort Gel Mask Anti Pores Masker Gel...</td>\n",
       "      <td>35</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8118</th>\n",
       "      <td>ZARA</td>\n",
       "      <td>304002157530</td>\n",
       "      <td>ZARA Eau De Parfum Hibiscus 90ml</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8119</th>\n",
       "      <td>ZARA</td>\n",
       "      <td>30400321119</td>\n",
       "      <td>ZARA Eau De Toilette Go Fruity 90ml</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>237002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8120</th>\n",
       "      <td>ZARA</td>\n",
       "      <td>30400320908</td>\n",
       "      <td>ZARA Eau De Toilette Peony 90ml</td>\n",
       "      <td>3</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>237002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8121</th>\n",
       "      <td>ZARA</td>\n",
       "      <td>30400439849</td>\n",
       "      <td>ZARA Eau De Toilette Twilight Mauve 90ml</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>237002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8122</th>\n",
       "      <td>ZWITSAL</td>\n",
       "      <td>8999999561567</td>\n",
       "      <td>ZWITSAL Eau De Zwitsal Body Mist 100ml</td>\n",
       "      <td>30</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>25210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8123 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Brand            SKU  \\\n",
       "0     ACNAWAY    10400614911   \n",
       "1     ACNAWAY    10100824612   \n",
       "2     ACNAWAY    10400517459   \n",
       "3     ACNAWAY   101001107647   \n",
       "4     ACNAWAY    10500637717   \n",
       "...       ...            ...   \n",
       "8118     ZARA   304002157530   \n",
       "8119     ZARA    30400321119   \n",
       "8120     ZARA    30400320908   \n",
       "8121     ZARA    30400439849   \n",
       "8122  ZWITSAL  8999999561567   \n",
       "\n",
       "                                                   Nama  Stock  Daily Sales  \\\n",
       "0     ACNAWAY 3 in 1 Acne Sun Serum Sunscreen Serum ...      0         0.00   \n",
       "1             ACNAWAY Mugwort Acne Clear Bar Soap 100gr      0         0.00   \n",
       "2     ACNAWAY Mugwort Daily Sunscreen Only For Acne ...      0         0.00   \n",
       "3     ACNAWAY Mugwort Gel Facial Wash Mugwort + Cent...      2         0.80   \n",
       "4     ACNAWAY Mugwort Gel Mask Anti Pores Masker Gel...     35         0.36   \n",
       "...                                                 ...    ...          ...   \n",
       "8118                   ZARA Eau De Parfum Hibiscus 90ml      0         0.00   \n",
       "8119                ZARA Eau De Toilette Go Fruity 90ml      7         0.00   \n",
       "8120                    ZARA Eau De Toilette Peony 90ml      3         0.02   \n",
       "8121           ZARA Eau De Toilette Twilight Mauve 90ml      8         0.00   \n",
       "8122             ZWITSAL Eau De Zwitsal Body Mist 100ml     30         1.41   \n",
       "\n",
       "      Max. Daily Sales  Lead Time  Max. Lead Time  Sedang PO  Min. Order  \\\n",
       "0                    0          4              23          0           1   \n",
       "1                    0          4              23         24           1   \n",
       "2                    0          4              23         16           1   \n",
       "3                    4          4              23         25           1   \n",
       "4                    8          4              23          0           1   \n",
       "...                ...        ...             ...        ...         ...   \n",
       "8118                 0          4              23          0           3   \n",
       "8119                 0          4              23          0           3   \n",
       "8120                 1          4              23          0           3   \n",
       "8121                 0          4              23          0           3   \n",
       "8122                 7          3              13          0           3   \n",
       "\n",
       "         HPP  \n",
       "0      57850  \n",
       "1      31000  \n",
       "2          0  \n",
       "3      31930  \n",
       "4      33908  \n",
       "...      ...  \n",
       "8118       0  \n",
       "8119  237002  \n",
       "8120  237002  \n",
       "8121  237002  \n",
       "8122   25210  \n",
       "\n",
       "[8123 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>SKU</th>\n",
       "      <th>Nama</th>\n",
       "      <th>Stock</th>\n",
       "      <th>Daily Sales</th>\n",
       "      <th>Max. Daily Sales</th>\n",
       "      <th>Lead Time</th>\n",
       "      <th>Max. Lead Time</th>\n",
       "      <th>Sedang PO</th>\n",
       "      <th>Min. Order</th>\n",
       "      <th>HPP</th>\n",
       "      <th>Lead Time Sedang PO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACNAWAY</td>\n",
       "      <td>10400614911</td>\n",
       "      <td>ACNAWAY 3 in 1 Acne Sun Serum Sunscreen Serum ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>57850</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACNAWAY</td>\n",
       "      <td>10100824612</td>\n",
       "      <td>ACNAWAY Mugwort Acne Clear Bar Soap 100gr</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>31000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACNAWAY</td>\n",
       "      <td>10400517459</td>\n",
       "      <td>ACNAWAY Mugwort Daily Sunscreen Only For Acne ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACNAWAY</td>\n",
       "      <td>101001107647</td>\n",
       "      <td>ACNAWAY Mugwort Gel Facial Wash Mugwort + Cent...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.80</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>31930</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACNAWAY</td>\n",
       "      <td>10500637717</td>\n",
       "      <td>ACNAWAY Mugwort Gel Mask Anti Pores Masker Gel...</td>\n",
       "      <td>35</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33908</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8118</th>\n",
       "      <td>ZARA</td>\n",
       "      <td>304002157530</td>\n",
       "      <td>ZARA Eau De Parfum Hibiscus 90ml</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8119</th>\n",
       "      <td>ZARA</td>\n",
       "      <td>30400321119</td>\n",
       "      <td>ZARA Eau De Toilette Go Fruity 90ml</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>237002</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8120</th>\n",
       "      <td>ZARA</td>\n",
       "      <td>30400320908</td>\n",
       "      <td>ZARA Eau De Toilette Peony 90ml</td>\n",
       "      <td>3</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>237002</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8121</th>\n",
       "      <td>ZARA</td>\n",
       "      <td>30400439849</td>\n",
       "      <td>ZARA Eau De Toilette Twilight Mauve 90ml</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>237002</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8122</th>\n",
       "      <td>ZWITSAL</td>\n",
       "      <td>8999999561567</td>\n",
       "      <td>ZWITSAL Eau De Zwitsal Body Mist 100ml</td>\n",
       "      <td>30</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>25210</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8123 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Brand            SKU  \\\n",
       "0     ACNAWAY    10400614911   \n",
       "1     ACNAWAY    10100824612   \n",
       "2     ACNAWAY    10400517459   \n",
       "3     ACNAWAY   101001107647   \n",
       "4     ACNAWAY    10500637717   \n",
       "...       ...            ...   \n",
       "8118     ZARA   304002157530   \n",
       "8119     ZARA    30400321119   \n",
       "8120     ZARA    30400320908   \n",
       "8121     ZARA    30400439849   \n",
       "8122  ZWITSAL  8999999561567   \n",
       "\n",
       "                                                   Nama  Stock  Daily Sales  \\\n",
       "0     ACNAWAY 3 in 1 Acne Sun Serum Sunscreen Serum ...      0         0.00   \n",
       "1             ACNAWAY Mugwort Acne Clear Bar Soap 100gr      0         0.00   \n",
       "2     ACNAWAY Mugwort Daily Sunscreen Only For Acne ...      0         0.00   \n",
       "3     ACNAWAY Mugwort Gel Facial Wash Mugwort + Cent...      2         0.80   \n",
       "4     ACNAWAY Mugwort Gel Mask Anti Pores Masker Gel...     35         0.36   \n",
       "...                                                 ...    ...          ...   \n",
       "8118                   ZARA Eau De Parfum Hibiscus 90ml      0         0.00   \n",
       "8119                ZARA Eau De Toilette Go Fruity 90ml      7         0.00   \n",
       "8120                    ZARA Eau De Toilette Peony 90ml      3         0.02   \n",
       "8121           ZARA Eau De Toilette Twilight Mauve 90ml      8         0.00   \n",
       "8122             ZWITSAL Eau De Zwitsal Body Mist 100ml     30         1.41   \n",
       "\n",
       "      Max. Daily Sales  Lead Time  Max. Lead Time  Sedang PO  Min. Order  \\\n",
       "0                    0          4              23          0           1   \n",
       "1                    0          4              23         24           1   \n",
       "2                    0          4              23         16           1   \n",
       "3                    4          4              23         25           1   \n",
       "4                    8          4              23          0           1   \n",
       "...                ...        ...             ...        ...         ...   \n",
       "8118                 0          4              23          0           3   \n",
       "8119                 0          4              23          0           3   \n",
       "8120                 1          4              23          0           3   \n",
       "8121                 0          4              23          0           3   \n",
       "8122                 7          3              13          0           3   \n",
       "\n",
       "         HPP  Lead Time Sedang PO  \n",
       "0      57850                    5  \n",
       "1      31000                    5  \n",
       "2          0                    5  \n",
       "3      31930                    5  \n",
       "4      33908                    5  \n",
       "...      ...                  ...  \n",
       "8118       0                    5  \n",
       "8119  237002                    5  \n",
       "8120  237002                    5  \n",
       "8121  237002                    5  \n",
       "8122   25210                    5  \n",
       "\n",
       "[8123 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame Info: Expected to have maximal non-null values...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8123 entries, 0 to 8122\n",
      "Data columns (total 12 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Brand                8123 non-null   object \n",
      " 1   SKU                  8123 non-null   int64  \n",
      " 2   Nama                 8123 non-null   object \n",
      " 3   Stock                8123 non-null   int64  \n",
      " 4   Daily Sales          8123 non-null   float64\n",
      " 5   Max. Daily Sales     8123 non-null   int64  \n",
      " 6   Lead Time            8123 non-null   int64  \n",
      " 7   Max. Lead Time       8123 non-null   int64  \n",
      " 8   Sedang PO            8123 non-null   int64  \n",
      " 9   Min. Order           8123 non-null   int64  \n",
      " 10  HPP                  8123 non-null   int64  \n",
      " 11  Lead Time Sedang PO  8123 non-null   int64  \n",
      "dtypes: float64(1), int64(9), object(2)\n",
      "memory usage: 761.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# First, convert object columns to numeric where possible\n",
    "numeric_columns = ['Stock', 'Daily Sales', 'Lead Time', 'Max. Daily Sales', 'Max. Lead Time']\n",
    "\n",
    "df_clean = df.copy()\n",
    "display('Raw DataFrame: ', df)\n",
    "\n",
    "# Convert all columns to numeric, coercing errors to NaN\n",
    "for col in numeric_columns:\n",
    "    df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce')\n",
    "\n",
    "# Now fill NA with 0 and convert to int\n",
    "df_clean = df_clean.fillna(0)\n",
    "\n",
    "# For non-numeric columns, keep them as they are\n",
    "non_numeric_columns = ['Brand', 'SKU']  # Add other non-numeric columns if needed\n",
    "for col in non_numeric_columns:\n",
    "    df_clean[col] = df[col]  # Keep original values\n",
    "\n",
    "# add new column 'Lead Time Sedang PO' default to 2 days\n",
    "df_clean['Lead Time Sedang PO'] = 5\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(\"Cleaned DataFrame:\")\n",
    "display(df_clean)\n",
    "\n",
    "# Show info of the cleaned DataFrame\n",
    "print(\"\\nDataFrame Info: Expected to have maximal non-null values...\")\n",
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482e2257",
   "metadata": {},
   "source": [
    "### Add Supply Chain params for AutoPO\n",
    "\n",
    "- Safety stock - (max sales x max lead time) - (avg sales x avg lead time)\n",
    "- Reorder point - avg sales x avg lead time + safety stock\n",
    "- Stock cover days (for 21 days) - avg sales x 21\n",
    "- RoP_Reference (1 -> RoP > Stock cover days, 0 -> RoP < Stock cover days)\n",
    "- Current stock days cover -> Current stock / avg sales\n",
    "- Is_open_po (1 -> Current Stock < Reorder point, 0 -> otherwise)\n",
    "- Initial_Qty_PO - Reorder point - Current stock\n",
    "\n",
    "- Is_emergency_PO - 1 -> Current stock days cover <= max lead time\n",
    "\n",
    "- Emergency_PO_Qty - (max lead time - Current stock days cover) x Avg sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683891c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>SKU</th>\n",
       "      <th>Nama</th>\n",
       "      <th>Stock</th>\n",
       "      <th>Daily Sales</th>\n",
       "      <th>Max. Daily Sales</th>\n",
       "      <th>Lead Time</th>\n",
       "      <th>Max. Lead Time</th>\n",
       "      <th>Sedang PO</th>\n",
       "      <th>Min. Order</th>\n",
       "      <th>HPP</th>\n",
       "      <th>Lead Time Sedang PO</th>\n",
       "      <th>Safety stock</th>\n",
       "      <th>Reorder point</th>\n",
       "      <th>Stock cover 30 days</th>\n",
       "      <th>current_stock_days_cover</th>\n",
       "      <th>is_open_po</th>\n",
       "      <th>initial_qty_po</th>\n",
       "      <th>emergency_po_qty</th>\n",
       "      <th>updated_regular_po_qty</th>\n",
       "      <th>final_updated_regular_po_qty</th>\n",
       "      <th>total_cost_emergency_po</th>\n",
       "      <th>total_cost_final_updated_regular_po</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACNAWAY</td>\n",
       "      <td>10400614911</td>\n",
       "      <td>ACNAWAY 3 in 1 Acne Sun Serum Sunscreen Serum ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>57850</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACNAWAY</td>\n",
       "      <td>10100824612</td>\n",
       "      <td>ACNAWAY Mugwort Acne Clear Bar Soap 100gr</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>31000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACNAWAY</td>\n",
       "      <td>10400517459</td>\n",
       "      <td>ACNAWAY Mugwort Daily Sunscreen Only For Acne ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACNAWAY</td>\n",
       "      <td>101001107647</td>\n",
       "      <td>ACNAWAY Mugwort Gel Facial Wash Mugwort + Cent...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.80</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>31930</td>\n",
       "      <td>5</td>\n",
       "      <td>89</td>\n",
       "      <td>93</td>\n",
       "      <td>24</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63860</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACNAWAY</td>\n",
       "      <td>10500637717</td>\n",
       "      <td>ACNAWAY Mugwort Gel Mask Anti Pores Masker Gel...</td>\n",
       "      <td>35</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33908</td>\n",
       "      <td>5</td>\n",
       "      <td>183</td>\n",
       "      <td>185</td>\n",
       "      <td>11</td>\n",
       "      <td>97.22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8118</th>\n",
       "      <td>ZARA</td>\n",
       "      <td>304002157530</td>\n",
       "      <td>ZARA Eau De Parfum Hibiscus 90ml</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8119</th>\n",
       "      <td>ZARA</td>\n",
       "      <td>30400321119</td>\n",
       "      <td>ZARA Eau De Toilette Go Fruity 90ml</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>237002</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8120</th>\n",
       "      <td>ZARA</td>\n",
       "      <td>30400320908</td>\n",
       "      <td>ZARA Eau De Toilette Peony 90ml</td>\n",
       "      <td>3</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>237002</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>150.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8121</th>\n",
       "      <td>ZARA</td>\n",
       "      <td>30400439849</td>\n",
       "      <td>ZARA Eau De Toilette Twilight Mauve 90ml</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>237002</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8122</th>\n",
       "      <td>ZWITSAL</td>\n",
       "      <td>8999999561567</td>\n",
       "      <td>ZWITSAL Eau De Zwitsal Body Mist 100ml</td>\n",
       "      <td>30</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>25210</td>\n",
       "      <td>5</td>\n",
       "      <td>87</td>\n",
       "      <td>92</td>\n",
       "      <td>43</td>\n",
       "      <td>21.28</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>327730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8123 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Brand            SKU  \\\n",
       "0     ACNAWAY    10400614911   \n",
       "1     ACNAWAY    10100824612   \n",
       "2     ACNAWAY    10400517459   \n",
       "3     ACNAWAY   101001107647   \n",
       "4     ACNAWAY    10500637717   \n",
       "...       ...            ...   \n",
       "8118     ZARA   304002157530   \n",
       "8119     ZARA    30400321119   \n",
       "8120     ZARA    30400320908   \n",
       "8121     ZARA    30400439849   \n",
       "8122  ZWITSAL  8999999561567   \n",
       "\n",
       "                                                   Nama  Stock  Daily Sales  \\\n",
       "0     ACNAWAY 3 in 1 Acne Sun Serum Sunscreen Serum ...      0         0.00   \n",
       "1             ACNAWAY Mugwort Acne Clear Bar Soap 100gr      0         0.00   \n",
       "2     ACNAWAY Mugwort Daily Sunscreen Only For Acne ...      0         0.00   \n",
       "3     ACNAWAY Mugwort Gel Facial Wash Mugwort + Cent...      2         0.80   \n",
       "4     ACNAWAY Mugwort Gel Mask Anti Pores Masker Gel...     35         0.36   \n",
       "...                                                 ...    ...          ...   \n",
       "8118                   ZARA Eau De Parfum Hibiscus 90ml      0         0.00   \n",
       "8119                ZARA Eau De Toilette Go Fruity 90ml      7         0.00   \n",
       "8120                    ZARA Eau De Toilette Peony 90ml      3         0.02   \n",
       "8121           ZARA Eau De Toilette Twilight Mauve 90ml      8         0.00   \n",
       "8122             ZWITSAL Eau De Zwitsal Body Mist 100ml     30         1.41   \n",
       "\n",
       "      Max. Daily Sales  Lead Time  Max. Lead Time  Sedang PO  Min. Order  \\\n",
       "0                    0          4              23          0           1   \n",
       "1                    0          4              23         24           1   \n",
       "2                    0          4              23         16           1   \n",
       "3                    4          4              23         25           1   \n",
       "4                    8          4              23          0           1   \n",
       "...                ...        ...             ...        ...         ...   \n",
       "8118                 0          4              23          0           3   \n",
       "8119                 0          4              23          0           3   \n",
       "8120                 1          4              23          0           3   \n",
       "8121                 0          4              23          0           3   \n",
       "8122                 7          3              13          0           3   \n",
       "\n",
       "         HPP  Lead Time Sedang PO  Safety stock  Reorder point  \\\n",
       "0      57850                    5             0              0   \n",
       "1      31000                    5             0              0   \n",
       "2          0                    5             0              0   \n",
       "3      31930                    5            89             93   \n",
       "4      33908                    5           183            185   \n",
       "...      ...                  ...           ...            ...   \n",
       "8118       0                    5             0              0   \n",
       "8119  237002                    5             0              0   \n",
       "8120  237002                    5            23             24   \n",
       "8121  237002                    5             0              0   \n",
       "8122   25210                    5            87             92   \n",
       "\n",
       "      Stock cover 30 days  current_stock_days_cover  is_open_po  \\\n",
       "0                       0                      0.00           0   \n",
       "1                       0                      0.00           0   \n",
       "2                       0                      0.00           0   \n",
       "3                      24                      2.50           1   \n",
       "4                      11                     97.22           0   \n",
       "...                   ...                       ...         ...   \n",
       "8118                    0                      0.00           0   \n",
       "8119                    0                      0.00           0   \n",
       "8120                    1                    150.00           0   \n",
       "8121                    0                      0.00           0   \n",
       "8122                   43                     21.28           1   \n",
       "\n",
       "      initial_qty_po  emergency_po_qty  updated_regular_po_qty  \\\n",
       "0                  0                 0                       0   \n",
       "1                  0                 0                       0   \n",
       "2                  0                 0                       0   \n",
       "3                  0                 2                       0   \n",
       "4                  0                 0                       0   \n",
       "...              ...               ...                     ...   \n",
       "8118               0                 0                       0   \n",
       "8119               0                 0                       0   \n",
       "8120               0                 0                       0   \n",
       "8121               0                 0                       0   \n",
       "8122              13                 0                      13   \n",
       "\n",
       "      final_updated_regular_po_qty  total_cost_emergency_po  \\\n",
       "0                                0                        0   \n",
       "1                                0                        0   \n",
       "2                                0                        0   \n",
       "3                                0                    63860   \n",
       "4                                0                        0   \n",
       "...                            ...                      ...   \n",
       "8118                             0                        0   \n",
       "8119                             0                        0   \n",
       "8120                             0                        0   \n",
       "8121                             0                        0   \n",
       "8122                            13                        0   \n",
       "\n",
       "      total_cost_final_updated_regular_po  \n",
       "0                                       0  \n",
       "1                                       0  \n",
       "2                                       0  \n",
       "3                                       0  \n",
       "4                                       0  \n",
       "...                                   ...  \n",
       "8118                                    0  \n",
       "8119                                    0  \n",
       "8120                                    0  \n",
       "8121                                    0  \n",
       "8122                               327730  \n",
       "\n",
       "[8123 rows x 23 columns]"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "# 1. Safety stock = (max sales x max lead time) - (avg sales x avg lead time)\n",
    "df_clean['Safety stock'] = (df_clean['Max. Daily Sales'] * df_clean['Max. Lead Time']) - (df_clean['Daily Sales'] * df_clean['Lead Time'])\n",
    "# round up safety stock\n",
    "df_clean['Safety stock'] = df_clean['Safety stock'].apply(lambda x: np.ceil(x)).astype(int)\n",
    "\n",
    "# 2. Reorder point = (avg sales x avg lead time) + safety stock\n",
    "df_clean['Reorder point'] = np.ceil((df_clean['Daily Sales'] * df_clean['Lead Time']) + \n",
    "                                   df_clean['Safety stock']).astype(int)\n",
    "\n",
    "# 3. Stock cover days (in Qty) for 30 days = avg sales x 30 \n",
    "df_clean['Stock cover 30 days'] = df_clean['Daily Sales'] * 30\n",
    "df_clean['Stock cover 30 days'] = df_clean['Stock cover 30 days'].apply(lambda x: np.ceil(x)).astype(int)\n",
    "\n",
    "# 5. Current stock days cover (in days) = Current stock / avg sales\n",
    "df_clean['current_stock_days_cover'] = (df_clean['Stock'].astype(float) * 1.0 ) / df_clean['Daily Sales'].astype(float)\n",
    "\n",
    "# 6. Is_open_po (1 -> Current stock < Reorder point, 0 -> otherwise)\n",
    "df_clean['is_open_po'] = np.where((df_clean['current_stock_days_cover'] <= 30) & (df_clean['Stock'] <= df_clean['Reorder point']), 1, 0)\n",
    "\n",
    "# 7. Initial_Qty_PO = Stock cover 30 days - Current stock - sedang PO\n",
    "df_clean['initial_qty_po'] = df_clean['Stock cover 30 days'] - df_clean['Stock'] - df_clean['Sedang PO']\n",
    "df_clean['initial_qty_po'] = np.where(df_clean['is_open_po'] == 1, df_clean['initial_qty_po'], 0)\n",
    "df_clean['initial_qty_po'] = df_clean['initial_qty_po'].apply(lambda x: x if x > 0 else 0).astype(int)\n",
    "\n",
    "# 9. Emergency_PO_Qty = (max lead time - Current stock days cover) x Avg sales\n",
    "# First, ensure 'Sedang PO' column exists and handle potential missing values\n",
    "if 'Sedang PO' not in df_clean.columns:\n",
    "    df_clean['Sedang PO'] = 0  # Default to 0 if column doesn't exist\n",
    "\n",
    "# Calculate emergency_po_qty based on the condition\n",
    "df_clean['emergency_po_qty'] = np.where(\n",
    "    df_clean['Sedang PO'] > 0,  # If there is 'Sedang PO' quantity\n",
    "    np.maximum(0, (df_clean['Lead Time Sedang PO'] - df_clean['current_stock_days_cover']) * \n",
    "              df_clean['Daily Sales']),\n",
    "    # Else use the original formula\n",
    "    np.ceil((df_clean['Max. Lead Time'] - df_clean['current_stock_days_cover']) * \n",
    "            df_clean['Daily Sales'])\n",
    ")\n",
    "\n",
    "# First, handle any infinite values and NaN values\n",
    "df_clean['emergency_po_qty'] = (\n",
    "    df_clean['emergency_po_qty']\n",
    "    .replace([np.inf, -np.inf], 0)  # Replace infinities with 0\n",
    "    .fillna(0)                      # Fill any remaining NaNs with 0\n",
    "    .astype(int)                    # Now safely convert to integers\n",
    ")\n",
    "\n",
    "# If you want to ensure no negative values (since it's a quantity)\n",
    "df_clean['emergency_po_qty'] = df_clean['emergency_po_qty'].clip(lower=0)\n",
    "\n",
    "# calculate updated po quantity\n",
    "df_clean['updated_regular_po_qty'] = df_clean['initial_qty_po'] - df_clean['emergency_po_qty']\n",
    "df_clean['updated_regular_po_qty'] = df_clean['updated_regular_po_qty'].apply(lambda x: x if x > 0 else 0).astype(int)\n",
    "\n",
    "# Final check updated regular PO - if less than Min. Order, use Min. Order qty\n",
    "df_clean['final_updated_regular_po_qty'] = np.where((df_clean['updated_regular_po_qty'] > 0) & (df_clean['updated_regular_po_qty'] < df_clean['Min. Order']), df_clean['Min. Order'], df_clean['updated_regular_po_qty'])\n",
    "\n",
    "\n",
    "# Calculate total cost (HPP * qty) for emergency PO and final updated regular PO\n",
    "df_clean['total_cost_emergency_po'] = df_clean['emergency_po_qty'] * df_clean['HPP']\n",
    "df_clean['total_cost_final_updated_regular_po'] = df_clean['final_updated_regular_po_qty'] * df_clean['HPP']\n",
    "\n",
    "# Handle any NaN or infinite values by replacing them with 0\n",
    "df_clean = df_clean.fillna(0)\n",
    "df_clean = df_clean.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "# Display the updated DataFrame with new columns\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ef8748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved to: output/result.csv\n"
     ]
    }
   ],
   "source": [
    "# Create output directory if it doesn't exist\n",
    "os.makedirs('output', exist_ok=True)\n",
    "\n",
    "# Export to CSV\n",
    "csv_path = 'output/result.csv'\n",
    "df_clean.to_csv(csv_path, index=False, sep=';', encoding='utf-8-sig')\n",
    "print(f\"CSV file saved to: {csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b178c94d",
   "metadata": {},
   "source": [
    "### Mapping Brand and SKU with supplier (add supplier column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89776ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in df_clean: 8123\n",
      "Total rows after merge: 8172\n",
      "\n",
      "Suppliers matched:\n",
      "- 'Miss Glam Padang' suppliers: 7809 rows\n",
      "- Other suppliers: 36 rows\n",
      "- No supplier data: 327 rows\n",
      "\n",
      "Results saved to: output/merged_with_suppliers.csv\n",
      "\n",
      "Sample of merged data (first 5 rows):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>SKU</th>\n",
       "      <th>Nama</th>\n",
       "      <th>Stock</th>\n",
       "      <th>Daily Sales</th>\n",
       "      <th>Max. Daily Sales</th>\n",
       "      <th>Lead Time</th>\n",
       "      <th>Max. Lead Time</th>\n",
       "      <th>Sedang PO</th>\n",
       "      <th>Min. Order</th>\n",
       "      <th>HPP</th>\n",
       "      <th>Lead Time Sedang PO</th>\n",
       "      <th>Safety stock</th>\n",
       "      <th>Reorder point</th>\n",
       "      <th>Stock cover 30 days</th>\n",
       "      <th>current_stock_days_cover</th>\n",
       "      <th>is_open_po</th>\n",
       "      <th>initial_qty_po</th>\n",
       "      <th>emergency_po_qty</th>\n",
       "      <th>updated_regular_po_qty</th>\n",
       "      <th>final_updated_regular_po_qty</th>\n",
       "      <th>total_cost_emergency_po</th>\n",
       "      <th>total_cost_final_updated_regular_po</th>\n",
       "      <th>No</th>\n",
       "      <th>ID Supplier</th>\n",
       "      <th>Nama Supplier</th>\n",
       "      <th>ID Brand</th>\n",
       "      <th>Nama Brand</th>\n",
       "      <th>ID Store</th>\n",
       "      <th>Nama Store</th>\n",
       "      <th>Hari Order</th>\n",
       "      <th>Min. Purchase</th>\n",
       "      <th>Trading Term</th>\n",
       "      <th>Promo Factor</th>\n",
       "      <th>Delay Factor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACNAWAY</td>\n",
       "      <td>10400614911</td>\n",
       "      <td>ACNAWAY 3 in 1 Acne Sun Serum Sunscreen Serum ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>57850</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2787.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>PT. BERSAMA DISTRIVERSA INDONESIA (DC CIPUTAT)</td>\n",
       "      <td>1480.00</td>\n",
       "      <td>ACNAWAY</td>\n",
       "      <td>7.00</td>\n",
       "      <td>Miss Glam Padang</td>\n",
       "      <td>2.00</td>\n",
       "      <td>500000.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACNAWAY</td>\n",
       "      <td>10100824612</td>\n",
       "      <td>ACNAWAY Mugwort Acne Clear Bar Soap 100gr</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>31000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2787.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>PT. BERSAMA DISTRIVERSA INDONESIA (DC CIPUTAT)</td>\n",
       "      <td>1480.00</td>\n",
       "      <td>ACNAWAY</td>\n",
       "      <td>7.00</td>\n",
       "      <td>Miss Glam Padang</td>\n",
       "      <td>2.00</td>\n",
       "      <td>500000.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACNAWAY</td>\n",
       "      <td>10400517459</td>\n",
       "      <td>ACNAWAY Mugwort Daily Sunscreen Only For Acne ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2787.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>PT. BERSAMA DISTRIVERSA INDONESIA (DC CIPUTAT)</td>\n",
       "      <td>1480.00</td>\n",
       "      <td>ACNAWAY</td>\n",
       "      <td>7.00</td>\n",
       "      <td>Miss Glam Padang</td>\n",
       "      <td>2.00</td>\n",
       "      <td>500000.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACNAWAY</td>\n",
       "      <td>101001107647</td>\n",
       "      <td>ACNAWAY Mugwort Gel Facial Wash Mugwort + Cent...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.80</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>31930</td>\n",
       "      <td>5</td>\n",
       "      <td>89</td>\n",
       "      <td>93</td>\n",
       "      <td>24</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63860</td>\n",
       "      <td>0</td>\n",
       "      <td>2787.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>PT. BERSAMA DISTRIVERSA INDONESIA (DC CIPUTAT)</td>\n",
       "      <td>1480.00</td>\n",
       "      <td>ACNAWAY</td>\n",
       "      <td>7.00</td>\n",
       "      <td>Miss Glam Padang</td>\n",
       "      <td>2.00</td>\n",
       "      <td>500000.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACNAWAY</td>\n",
       "      <td>10500637717</td>\n",
       "      <td>ACNAWAY Mugwort Gel Mask Anti Pores Masker Gel...</td>\n",
       "      <td>35</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33908</td>\n",
       "      <td>5</td>\n",
       "      <td>183</td>\n",
       "      <td>185</td>\n",
       "      <td>11</td>\n",
       "      <td>97.22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2787.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>PT. BERSAMA DISTRIVERSA INDONESIA (DC CIPUTAT)</td>\n",
       "      <td>1480.00</td>\n",
       "      <td>ACNAWAY</td>\n",
       "      <td>7.00</td>\n",
       "      <td>Miss Glam Padang</td>\n",
       "      <td>2.00</td>\n",
       "      <td>500000.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Brand           SKU                                               Nama  \\\n",
       "0  ACNAWAY   10400614911  ACNAWAY 3 in 1 Acne Sun Serum Sunscreen Serum ...   \n",
       "1  ACNAWAY   10100824612          ACNAWAY Mugwort Acne Clear Bar Soap 100gr   \n",
       "2  ACNAWAY   10400517459  ACNAWAY Mugwort Daily Sunscreen Only For Acne ...   \n",
       "3  ACNAWAY  101001107647  ACNAWAY Mugwort Gel Facial Wash Mugwort + Cent...   \n",
       "4  ACNAWAY   10500637717  ACNAWAY Mugwort Gel Mask Anti Pores Masker Gel...   \n",
       "\n",
       "   Stock  Daily Sales  Max. Daily Sales  Lead Time  Max. Lead Time  Sedang PO  \\\n",
       "0      0         0.00                 0          4              23          0   \n",
       "1      0         0.00                 0          4              23         24   \n",
       "2      0         0.00                 0          4              23         16   \n",
       "3      2         0.80                 4          4              23         25   \n",
       "4     35         0.36                 8          4              23          0   \n",
       "\n",
       "   Min. Order    HPP  Lead Time Sedang PO  Safety stock  Reorder point  \\\n",
       "0           1  57850                    5             0              0   \n",
       "1           1  31000                    5             0              0   \n",
       "2           1      0                    5             0              0   \n",
       "3           1  31930                    5            89             93   \n",
       "4           1  33908                    5           183            185   \n",
       "\n",
       "   Stock cover 30 days  current_stock_days_cover  is_open_po  initial_qty_po  \\\n",
       "0                    0                      0.00           0               0   \n",
       "1                    0                      0.00           0               0   \n",
       "2                    0                      0.00           0               0   \n",
       "3                   24                      2.50           1               0   \n",
       "4                   11                     97.22           0               0   \n",
       "\n",
       "   emergency_po_qty  updated_regular_po_qty  final_updated_regular_po_qty  \\\n",
       "0                 0                       0                             0   \n",
       "1                 0                       0                             0   \n",
       "2                 0                       0                             0   \n",
       "3                 2                       0                             0   \n",
       "4                 0                       0                             0   \n",
       "\n",
       "   total_cost_emergency_po  total_cost_final_updated_regular_po      No  \\\n",
       "0                        0                                    0 2787.00   \n",
       "1                        0                                    0 2787.00   \n",
       "2                        0                                    0 2787.00   \n",
       "3                    63860                                    0 2787.00   \n",
       "4                        0                                    0 2787.00   \n",
       "\n",
       "  ID Supplier                                   Nama Supplier  ID Brand  \\\n",
       "0        1.00  PT. BERSAMA DISTRIVERSA INDONESIA (DC CIPUTAT)   1480.00   \n",
       "1        1.00  PT. BERSAMA DISTRIVERSA INDONESIA (DC CIPUTAT)   1480.00   \n",
       "2        1.00  PT. BERSAMA DISTRIVERSA INDONESIA (DC CIPUTAT)   1480.00   \n",
       "3        1.00  PT. BERSAMA DISTRIVERSA INDONESIA (DC CIPUTAT)   1480.00   \n",
       "4        1.00  PT. BERSAMA DISTRIVERSA INDONESIA (DC CIPUTAT)   1480.00   \n",
       "\n",
       "  Nama Brand  ID Store        Nama Store  Hari Order  Min. Purchase  \\\n",
       "0    ACNAWAY      7.00  Miss Glam Padang        2.00      500000.00   \n",
       "1    ACNAWAY      7.00  Miss Glam Padang        2.00      500000.00   \n",
       "2    ACNAWAY      7.00  Miss Glam Padang        2.00      500000.00   \n",
       "3    ACNAWAY      7.00  Miss Glam Padang        2.00      500000.00   \n",
       "4    ACNAWAY      7.00  Miss Glam Padang        2.00      500000.00   \n",
       "\n",
       "   Trading Term Promo Factor Delay Factor  \n",
       "0          0.00                            \n",
       "1          0.00                            \n",
       "2          0.00                            \n",
       "3          0.00                            \n",
       "4          0.00                            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Make copies to avoid modifying originals\n",
    "df_clean_trimmed = df_clean.copy()\n",
    "raw_supplier_trimmed = raw_supplier_df.copy()\n",
    "\n",
    "# Trim whitespace from brand names\n",
    "df_clean_trimmed['Brand'] = df_clean_trimmed['Brand'].str.strip()\n",
    "raw_supplier_trimmed['Nama Brand'] = raw_supplier_trimmed['Nama Brand'].str.strip()\n",
    "\n",
    "# First, get all Padang suppliers\n",
    "padang_suppliers = raw_supplier_trimmed[\n",
    "    raw_supplier_trimmed['Nama Store'] == 'Miss Glam Padang'\n",
    "]\n",
    "\n",
    "# Then get all other suppliers (non-Padang)\n",
    "other_suppliers = raw_supplier_trimmed[\n",
    "    raw_supplier_trimmed['Nama Store'] != 'Miss Glam Padang'\n",
    "]\n",
    "\n",
    "# Step 1: Left join with Padang suppliers first (priority)\n",
    "merged_df = pd.merge(\n",
    "    df_clean_trimmed,\n",
    "    padang_suppliers,\n",
    "    left_on='Brand',\n",
    "    right_on='Nama Brand',\n",
    "    how='left',\n",
    "    suffixes=('_clean', '_supplier')\n",
    ")\n",
    "\n",
    "# Step 2: For rows without Padang supplier, try to find other suppliers\n",
    "# Get the indices of rows that didn't get a match with Padang suppliers\n",
    "no_padang_match = merged_df[merged_df['Nama Brand'].isna()].index\n",
    "\n",
    "if len(no_padang_match) > 0:\n",
    "    # Get the brands that need non-Padang suppliers\n",
    "    brands_needing_suppliers = merged_df.loc[no_padang_match, 'Brand'].unique()\n",
    "    \n",
    "    # Get the first matching supplier for each brand (you can change this logic if needed)\n",
    "    first_supplier_per_brand = other_suppliers.drop_duplicates(subset='Nama Brand')\n",
    "    \n",
    "    # Update the rows that didn't have Padang suppliers\n",
    "    for brand in brands_needing_suppliers:\n",
    "        supplier_data = first_supplier_per_brand[first_supplier_per_brand['Nama Brand'] == brand]\n",
    "        if not supplier_data.empty:\n",
    "            # Update the corresponding rows in merged_df\n",
    "            brand_mask = (merged_df['Brand'] == brand) & (merged_df['Nama Brand'].isna())\n",
    "            for col in supplier_data.columns:\n",
    "                if col in merged_df.columns and col != 'Brand':  # Don't overwrite the Brand column\n",
    "                    merged_df.loc[brand_mask, col] = supplier_data[col].values[0]\n",
    "\n",
    "# Clean up: For any remaining NaN values in supplier columns, fill with empty string or as needed\n",
    "supplier_columns = [\n",
    "    'ID Supplier', 'Nama Supplier', 'ID Brand', 'ID Store', \n",
    "    'Nama Store', 'Hari Order', 'Min. Purchase', 'Trading Term',\n",
    "    'Promo Factor', 'Delay Factor'\n",
    "]\n",
    "\n",
    "for col in supplier_columns:\n",
    "    if col in merged_df.columns:\n",
    "        if merged_df[col].dtype == 'object':\n",
    "            merged_df[col] = merged_df[col].fillna('')\n",
    "        else:\n",
    "            merged_df[col] = merged_df[col].fillna(0)\n",
    "\n",
    "# Show summary\n",
    "print(f\"Total rows in df_clean: {len(df_clean_trimmed)}\")\n",
    "print(f\"Total rows after merge: {len(merged_df)}\")\n",
    "\n",
    "# Count how many rows got Padang suppliers vs other suppliers vs no suppliers\n",
    "padang_count = (merged_df['Nama Store'] == 'Miss Glam Padang').sum()\n",
    "other_supplier_count = ((merged_df['Nama Store'] != 'Miss Glam Padang') & \n",
    "                       (merged_df['Nama Store'] != '')).sum()\n",
    "no_supplier = (merged_df['Nama Store'] == '').sum()\n",
    "\n",
    "print(f\"\\nSuppliers matched:\")\n",
    "print(f\"- 'Miss Glam Padang' suppliers: {padang_count} rows\")\n",
    "print(f\"- Other suppliers: {other_supplier_count} rows\")\n",
    "print(f\"- No supplier data: {no_supplier} rows\")\n",
    "\n",
    "# Save the result\n",
    "os.makedirs('output', exist_ok=True)\n",
    "output_path = 'output/merged_with_suppliers.csv'\n",
    "merged_df.to_csv(output_path, index=False, sep=';', encoding='utf-8-sig')\n",
    "print(f\"\\nResults saved to: {output_path}\")\n",
    "\n",
    "# Show a sample of the results\n",
    "print(\"\\nSample of merged data (first 5 rows):\")\n",
    "display(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627b2bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6943 brand/SKU combinations with multiple suppliers\n",
      "\n",
      "Sample of items with multiple suppliers:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>SKU</th>\n",
       "      <th>Supplier_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACNEMED</td>\n",
       "      <td>8995232702124</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACNES</td>\n",
       "      <td>8992821100293</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ACNES</td>\n",
       "      <td>8992821100309</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ACNES</td>\n",
       "      <td>8992821100323</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ACNES</td>\n",
       "      <td>8992821100354</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Brand            SKU  Supplier_Count\n",
       "6   ACNEMED  8995232702124               2\n",
       "7     ACNES  8992821100293              10\n",
       "8     ACNES  8992821100309              10\n",
       "9     ACNES  8992821100323              10\n",
       "10    ACNES  8992821100354              10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detailed supplier information for multi-supplier items:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>SKU</th>\n",
       "      <th>Nama Supplier</th>\n",
       "      <th>Nama Store</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACNEMED</td>\n",
       "      <td>8995232702124</td>\n",
       "      <td>PT. PENTA VALENT - PPN (PDG)</td>\n",
       "      <td>Miss Glam Padang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACNEMED</td>\n",
       "      <td>8995232702124</td>\n",
       "      <td>PT. PENTA VALENT - PPN (PDG)</td>\n",
       "      <td>Miss Glam Damar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACNEMED</td>\n",
       "      <td>8995232702124</td>\n",
       "      <td>PT. PENTA VALENT - PPN (PDG)</td>\n",
       "      <td>Miss Glam Payakumbuh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACNEMED</td>\n",
       "      <td>8995232702124</td>\n",
       "      <td>PT. PENTA VALENT - PPN (PDG)</td>\n",
       "      <td>Miss Glam Solok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACNEMED</td>\n",
       "      <td>8995232702124</td>\n",
       "      <td>PT. PENTA VALENT - PPN (PDG)</td>\n",
       "      <td>Miss Glam Sutomo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220564</th>\n",
       "      <td>ZWITSAL</td>\n",
       "      <td>8999999561567</td>\n",
       "      <td>PT. SINARMAS DISTRIBUSI NUSANTARA - PPN (BKL)</td>\n",
       "      <td>Miss Glam Bengkulu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220565</th>\n",
       "      <td>ZWITSAL</td>\n",
       "      <td>8999999561567</td>\n",
       "      <td>PT. TEMAN JAYA ABADI - PPN (PKP)</td>\n",
       "      <td>Miss Glam Bangka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220566</th>\n",
       "      <td>ZWITSAL</td>\n",
       "      <td>8999999561567</td>\n",
       "      <td>PT. USAHA BERSAMA NATAR - PPN (LPG)</td>\n",
       "      <td>Miss Glam Lampung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220567</th>\n",
       "      <td>ZWITSAL</td>\n",
       "      <td>8999999561567</td>\n",
       "      <td>PT. USAHA BERSAMA NATAR - PPN (LPG)</td>\n",
       "      <td>Miss Glam Kedaton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220568</th>\n",
       "      <td>ZWITSAL</td>\n",
       "      <td>8999999561567</td>\n",
       "      <td>RIZANO - PPN (BKT)</td>\n",
       "      <td>Miss Glam Bukittinggi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>220092 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Brand            SKU                                  Nama Supplier  \\\n",
       "0       ACNEMED  8995232702124                   PT. PENTA VALENT - PPN (PDG)   \n",
       "1       ACNEMED  8995232702124                   PT. PENTA VALENT - PPN (PDG)   \n",
       "2       ACNEMED  8995232702124                   PT. PENTA VALENT - PPN (PDG)   \n",
       "3       ACNEMED  8995232702124                   PT. PENTA VALENT - PPN (PDG)   \n",
       "4       ACNEMED  8995232702124                   PT. PENTA VALENT - PPN (PDG)   \n",
       "...         ...            ...                                            ...   \n",
       "220564  ZWITSAL  8999999561567  PT. SINARMAS DISTRIBUSI NUSANTARA - PPN (BKL)   \n",
       "220565  ZWITSAL  8999999561567               PT. TEMAN JAYA ABADI - PPN (PKP)   \n",
       "220566  ZWITSAL  8999999561567            PT. USAHA BERSAMA NATAR - PPN (LPG)   \n",
       "220567  ZWITSAL  8999999561567            PT. USAHA BERSAMA NATAR - PPN (LPG)   \n",
       "220568  ZWITSAL  8999999561567                             RIZANO - PPN (BKT)   \n",
       "\n",
       "                   Nama Store  \n",
       "0            Miss Glam Padang  \n",
       "1             Miss Glam Damar  \n",
       "2        Miss Glam Payakumbuh  \n",
       "3             Miss Glam Solok  \n",
       "4            Miss Glam Sutomo  \n",
       "...                       ...  \n",
       "220564     Miss Glam Bengkulu  \n",
       "220565       Miss Glam Bangka  \n",
       "220566      Miss Glam Lampung  \n",
       "220567      Miss Glam Kedaton  \n",
       "220568  Miss Glam Bukittinggi  \n",
       "\n",
       "[220092 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found matching SKUs in df_clean:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>SKU</th>\n",
       "      <th>Nama</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACNEMED</td>\n",
       "      <td>8995232702124</td>\n",
       "      <td>ACNEMED Facial Wash For Oily Skin 100gr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ACNES</td>\n",
       "      <td>8992821100309</td>\n",
       "      <td>ACNES Creamy Wash 100gr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ACNES</td>\n",
       "      <td>8992821100293</td>\n",
       "      <td>ACNES Foaming Wash 100ml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ACNES</td>\n",
       "      <td>8992821100354</td>\n",
       "      <td>ACNES Oil Control Film isi 50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ACNES</td>\n",
       "      <td>8992821100323</td>\n",
       "      <td>ACNES Sealing Jell Gel 18gr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Brand            SKU                                     Nama\n",
       "6   ACNEMED  8995232702124  ACNEMED Facial Wash For Oily Skin 100gr\n",
       "9     ACNES  8992821100309                  ACNES Creamy Wash 100gr\n",
       "14    ACNES  8992821100293                 ACNES Foaming Wash 100ml\n",
       "17    ACNES  8992821100354            ACNES Oil Control Film isi 50\n",
       "24    ACNES  8992821100323              ACNES Sealing Jell Gel 18gr"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Merge df_clean with raw_supplier_df to see all supplier matches\n",
    "all_suppliers_merge = pd.merge(\n",
    "    df_clean_trimmed,\n",
    "    raw_supplier_trimmed,\n",
    "    left_on='Brand',\n",
    "    right_on='Nama Brand',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Group by Brand and SKU to count unique suppliers\n",
    "supplier_counts = all_suppliers_merge.groupby(['Brand', 'SKU'])['Nama Supplier'].nunique().reset_index()\n",
    "supplier_counts.columns = ['Brand', 'SKU', 'Supplier_Count']\n",
    "\n",
    "# Filter for brands/SKUs with multiple suppliers\n",
    "multi_supplier_items = supplier_counts[supplier_counts['Supplier_Count'] > 1]\n",
    "\n",
    "print(f\"Found {len(multi_supplier_items)} brand/SKU combinations with multiple suppliers\")\n",
    "print(\"\\nSample of items with multiple suppliers:\")\n",
    "display(multi_supplier_items.head())\n",
    "\n",
    "# If you want to see the actual supplier details for these items\n",
    "if not multi_supplier_items.empty:\n",
    "    print(\"\\nDetailed supplier information for multi-supplier items:\")\n",
    "    multi_supplier_details = all_suppliers_merge.merge(\n",
    "        multi_supplier_items[['Brand', 'SKU']],\n",
    "        on=['Brand', 'SKU']\n",
    "    )\n",
    "    display(multi_supplier_details[['Brand', 'SKU', 'Nama Supplier', 'Nama Store']].drop_duplicates().sort_values(['Brand', 'SKU']))\n",
    "\n",
    "    # List of SKUs to check\n",
    "skus_to_check = [\n",
    "    '8995232702124',  # ACNEMED\n",
    "    '8992821100293',  # ACNES\n",
    "    '8992821100309',  # ACNES\n",
    "    '8992821100323',  # ACNES\n",
    "    '8992821100354'   # ACNES\n",
    "]\n",
    "\n",
    "# Convert SKUs to integers (since they appear as integers in df_clean)\n",
    "skus_to_check = [int(sku) for sku in skus_to_check]\n",
    "\n",
    "# Check if these SKUs exist in df_clean\n",
    "found_skus = merged_df[merged_df['SKU'].isin(skus_to_check)]\n",
    "\n",
    "if not found_skus.empty:\n",
    "    print(\"Found matching SKUs in df_clean:\")\n",
    "    display(found_skus[['Brand', 'SKU', 'Nama']])\n",
    "else:\n",
    "    print(\"None of these SKUs were found in df_clean.\")\n",
    "    print(\"\\nChecking if there are any similar SKUs...\")\n",
    "    \n",
    "    # Check for any SKUs that contain these numbers\n",
    "    for sku in skus_to_check:\n",
    "        similar = merged_df[merged_df['SKU'].astype(str).str.contains(str(sku)[:8])]\n",
    "        if not similar.empty:\n",
    "            print(f\"\\nSKUs similar to {sku}:\")\n",
    "            display(similar[['Brand', 'SKU', 'Nama']])\n",
    "    \n",
    "    # Check the data types to ensure we're comparing correctly\n",
    "    print(\"\\nData type of SKU column:\", merged_df['SKU'].dtype)\n",
    "    print(\"Sample SKUs from df_clean:\", merged_df['SKU'].head().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d05a03",
   "metadata": {},
   "source": [
    "### Find brands who are missing suppliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c74465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of brands in df_clean: 430\n",
      "Number of brands in raw_supplier_df: 500\n",
      "\n",
      "Number of brands missing supplier data: 58\n",
      "\n",
      "First 20 missing brands (alphabetical order):\n",
      "['AHE', 'AIUEO', 'AVAIL', 'AWDAY', 'B.U.T', 'BEAUDELAB', \"BENING'S\", 'BHUMI', 'BROWIE', 'CELLUVIE', 'COLAB', 'DEATH POMADE', 'DOM POMADE', 'FLIMTY', 'GLOSSMEN', 'GOSMILE', 'HAIR & ME', 'HALOCA BEAUTY', 'HNH', 'INITO']\n",
      "\n",
      "Top 20 missing brands by row count:\n",
      "Brand\n",
      "MYKONOS             64\n",
      "JACQUELLE BEAUTE    35\n",
      "SOME BY MI          30\n",
      "MEZUCA              15\n",
      "MERCREDI            13\n",
      "MAIMEITE            12\n",
      "SECRET GARDEN       10\n",
      "ROSE ALL DAY         8\n",
      "RAECCA               8\n",
      "SLEEPOVER            7\n",
      "SEBAMED              7\n",
      "VIO                  7\n",
      "OLAY                 7\n",
      "BENING'S             6\n",
      "GOSMILE              6\n",
      "NEW SKIN             5\n",
      "MISS TI              5\n",
      "M&S BEAUTY           4\n",
      "MARKS & SPENCER      4\n",
      "NO BAD HAIR          3\n",
      "B.U.T                3\n",
      "AVAIL                3\n",
      "PINKROULETTE         3\n",
      "AIUEO                3\n",
      "COLAB                3\n",
      "HAIR & ME            3\n",
      "LA PERSONAL          3\n",
      "KOSEA                3\n",
      "KALON                3\n",
      "FLIMTY               3\n",
      "ITS GLOW             3\n",
      "INITO                3\n",
      "LITTLE FAIRY         3\n",
      "NARA                 2\n",
      "PHILOCALY            2\n",
      "SOONAFTER            2\n",
      "MABELLO              2\n",
      "HNH                  2\n",
      "DOM POMADE           2\n",
      "DEATH POMADE         2\n",
      "WET N WILD           1\n",
      "WAK DOYOK            1\n",
      "REJOICE              1\n",
      "VELLS BEAUTY         1\n",
      "SHEEBY               1\n",
      "AHE                  1\n",
      "MUSIC FLOWER         1\n",
      "MKB                  1\n",
      "MALIAN               1\n",
      "JAGIYA               1\n",
      "HALOCA BEAUTY        1\n",
      "GLOSSMEN             1\n",
      "CELLUVIE             1\n",
      "BROWIE               1\n",
      "BHUMI                1\n",
      "BEAUDELAB            1\n",
      "AWDAY                1\n",
      "YP LOGY              1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Find brands in df_clean that don't have a match in raw_supplier_df\n",
    "missing_brands = set(df_clean['Brand']) - set(raw_supplier_df['Nama Brand'].dropna().unique())\n",
    "\n",
    "print(f\"Number of brands in df_clean: {len(df_clean['Brand'].unique())}\")\n",
    "print(f\"Number of brands in raw_supplier_df: {len(raw_supplier_df['Nama Brand'].unique())}\")\n",
    "print(f\"\\nNumber of brands missing supplier data: {len(missing_brands)}\")\n",
    "print(\"\\nFirst 20 missing brands (alphabetical order):\")\n",
    "print(sorted(list(missing_brands))[:20])\n",
    "\n",
    "# Count how many rows are affected per missing brand\n",
    "missing_brand_counts = df_clean[df_clean['Brand'].isin(missing_brands)]['Brand'].value_counts()\n",
    "print(\"\\nTop 20 missing brands by row count:\")\n",
    "print(missing_brand_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8564e9",
   "metadata": {},
   "source": [
    "# Output grouped data per one brand and one SKU to separate files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7f4d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been organized into supplier and brand-based folders in 'output_po'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Create output directory\n",
    "output_dir = 'output_po'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Create a directory for brands without suppliers\n",
    "no_supplier_dir = os.path.join(output_dir, '0_no_suppliers')\n",
    "os.makedirs(no_supplier_dir, exist_ok=True)\n",
    "\n",
    "# Function to sanitize folder names\n",
    "def sanitize_folder_name(name):\n",
    "    # Remove or replace invalid characters\n",
    "    invalid_chars = '<>:\"/\\\\|?*'\n",
    "    for char in invalid_chars:\n",
    "        name = name.replace(char, '_')\n",
    "    return name.strip()\n",
    "\n",
    "# Process each group\n",
    "for (supplier_id, supplier_name, brand), group in final_df.groupby(['ID Supplier', 'Nama Supplier', 'Brand']):\n",
    "    # Skip if no supplier (shouldn't happen as we replaced NaN with defaults)\n",
    "    if pd.isna(supplier_id) or not supplier_name:\n",
    "        # Save to no_supplier_dir\n",
    "        brand_file = os.path.join(no_supplier_dir, f'{sanitize_folder_name(brand)}.csv')\n",
    "        group.to_csv(brand_file, index=False, sep=';', encoding='utf-8-sig')\n",
    "        continue\n",
    "    \n",
    "    # Create supplier directory\n",
    "    supplier_dir = os.path.join(output_dir, f'{int(supplier_id)}_{sanitize_folder_name(supplier_name)}')\n",
    "    os.makedirs(supplier_dir, exist_ok=True)\n",
    "    \n",
    "    # Save brand file\n",
    "    brand_file = os.path.join(supplier_dir, f'{sanitize_folder_name(brand)}.csv')\n",
    "    group.to_csv(brand_file, index=False, sep=';', encoding='utf-8-sig')\n",
    "\n",
    "print(\"Data has been organized into supplier and brand-based folders in 'output_po'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afb6ba5",
   "metadata": {},
   "source": [
    "# Final batch process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da39de54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading supplier data...\n",
      "Parsing Padang data...\n",
      "Padang data loaded successfully..\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>Brand</th>\n",
       "      <th>SKU</th>\n",
       "      <th>Nama</th>\n",
       "      <th>HPP</th>\n",
       "      <th>Harga</th>\n",
       "      <th>Ranking</th>\n",
       "      <th>Grade</th>\n",
       "      <th>Kategori Brand</th>\n",
       "      <th>Kategori</th>\n",
       "      <th>...</th>\n",
       "      <th>Siklus</th>\n",
       "      <th>[Brand] Promo Factor</th>\n",
       "      <th>[Brand] Delay Factor</th>\n",
       "      <th>[SKU] Promo Factor</th>\n",
       "      <th>[SKU] Delay Factor</th>\n",
       "      <th>[Master - SKU] Promo Factor</th>\n",
       "      <th>[Master - SKU] Delay Factor</th>\n",
       "      <th>Stock Cover</th>\n",
       "      <th>Days to Backup</th>\n",
       "      <th>Qty to Backup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ACNAWAY</td>\n",
       "      <td>101001107647</td>\n",
       "      <td>ACNAWAY Mugwort Gel Facial Wash Mugwort + Cent...</td>\n",
       "      <td>31930</td>\n",
       "      <td>42000</td>\n",
       "      <td>1193</td>\n",
       "      <td>A</td>\n",
       "      <td>BRAND VIRAL</td>\n",
       "      <td>Face Cleansing</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ACNAWAY</td>\n",
       "      <td>10500637717</td>\n",
       "      <td>ACNAWAY Mugwort Gel Mask Anti Pores Masker Gel...</td>\n",
       "      <td>33908</td>\n",
       "      <td>45000</td>\n",
       "      <td>1669</td>\n",
       "      <td>A</td>\n",
       "      <td>BRAND VIRAL</td>\n",
       "      <td>Face Mask</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ACNAWAY</td>\n",
       "      <td>10300721756</td>\n",
       "      <td>ACNAWAY Mugwort Water Gel Moisturizer with Mug...</td>\n",
       "      <td>30928</td>\n",
       "      <td>45000</td>\n",
       "      <td>1485</td>\n",
       "      <td>A</td>\n",
       "      <td>BRAND VIRAL</td>\n",
       "      <td>Moisturizer</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.71</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>ACNEMED</td>\n",
       "      <td>8995232702124</td>\n",
       "      <td>ACNEMED Facial Wash For Oily Skin 100gr</td>\n",
       "      <td>30220</td>\n",
       "      <td>36500</td>\n",
       "      <td>4690</td>\n",
       "      <td>B*</td>\n",
       "      <td>BEAUTY MATURE</td>\n",
       "      <td>Face Cleansing</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>ACNES</td>\n",
       "      <td>8992821102372</td>\n",
       "      <td>ACNES Complete White Face Wash 100gr</td>\n",
       "      <td>26623</td>\n",
       "      <td>33500</td>\n",
       "      <td>1026</td>\n",
       "      <td>A</td>\n",
       "      <td>BEAUTY MATURE</td>\n",
       "      <td>Face Cleansing</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>ACNES</td>\n",
       "      <td>8992821102365</td>\n",
       "      <td>ACNES Complete White Face Wash 50gr</td>\n",
       "      <td>15974</td>\n",
       "      <td>19500</td>\n",
       "      <td>634</td>\n",
       "      <td>A</td>\n",
       "      <td>BEAUTY MATURE</td>\n",
       "      <td>Face Cleansing</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>50.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>ACNES</td>\n",
       "      <td>8992821100309</td>\n",
       "      <td>ACNES Creamy Wash 100gr</td>\n",
       "      <td>25395</td>\n",
       "      <td>31000</td>\n",
       "      <td>604</td>\n",
       "      <td>A</td>\n",
       "      <td>BEAUTY MATURE</td>\n",
       "      <td>Face Cleansing</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>50.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>ACNES</td>\n",
       "      <td>8992821100392</td>\n",
       "      <td>ACNES Creamy Wash 50gr</td>\n",
       "      <td>15155</td>\n",
       "      <td>18500</td>\n",
       "      <td>669</td>\n",
       "      <td>A</td>\n",
       "      <td>BEAUTY MATURE</td>\n",
       "      <td>Face Cleansing</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>50.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>ACNES</td>\n",
       "      <td>8992821102396</td>\n",
       "      <td>ACNES Deep Pore Cleanser Face Wash 100g</td>\n",
       "      <td>26623</td>\n",
       "      <td>32500</td>\n",
       "      <td>979</td>\n",
       "      <td>A</td>\n",
       "      <td>BEAUTY MATURE</td>\n",
       "      <td>Face Cleansing</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>ACNES</td>\n",
       "      <td>8992821102389</td>\n",
       "      <td>ACNES Deep Pore Cleanser Face Wash 50gr</td>\n",
       "      <td>15974</td>\n",
       "      <td>19500</td>\n",
       "      <td>815</td>\n",
       "      <td>A</td>\n",
       "      <td>BEAUTY MATURE</td>\n",
       "      <td>Face Cleansing</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>50.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   No    Brand            SKU  \\\n",
       "0   1  ACNAWAY   101001107647   \n",
       "1   2  ACNAWAY    10500637717   \n",
       "2   3  ACNAWAY    10300721756   \n",
       "3   4  ACNEMED  8995232702124   \n",
       "4   5    ACNES  8992821102372   \n",
       "5   6    ACNES  8992821102365   \n",
       "6   7    ACNES  8992821100309   \n",
       "7   8    ACNES  8992821100392   \n",
       "8   9    ACNES  8992821102396   \n",
       "9  10    ACNES  8992821102389   \n",
       "\n",
       "                                                Nama    HPP  Harga  Ranking  \\\n",
       "0  ACNAWAY Mugwort Gel Facial Wash Mugwort + Cent...  31930  42000     1193   \n",
       "1  ACNAWAY Mugwort Gel Mask Anti Pores Masker Gel...  33908  45000     1669   \n",
       "2  ACNAWAY Mugwort Water Gel Moisturizer with Mug...  30928  45000     1485   \n",
       "3            ACNEMED Facial Wash For Oily Skin 100gr  30220  36500     4690   \n",
       "4               ACNES Complete White Face Wash 100gr  26623  33500     1026   \n",
       "5                ACNES Complete White Face Wash 50gr  15974  19500      634   \n",
       "6                            ACNES Creamy Wash 100gr  25395  31000      604   \n",
       "7                             ACNES Creamy Wash 50gr  15155  18500      669   \n",
       "8            ACNES Deep Pore Cleanser Face Wash 100g  26623  32500      979   \n",
       "9            ACNES Deep Pore Cleanser Face Wash 50gr  15974  19500      815   \n",
       "\n",
       "  Grade Kategori Brand        Kategori  ... Siklus  [Brand] Promo Factor  \\\n",
       "0     A    BRAND VIRAL  Face Cleansing  ...     21                     0   \n",
       "1     A    BRAND VIRAL       Face Mask  ...     21                     0   \n",
       "2     A    BRAND VIRAL     Moisturizer  ...     21                     0   \n",
       "3    B*  BEAUTY MATURE  Face Cleansing  ...     21                     0   \n",
       "4     A  BEAUTY MATURE  Face Cleansing  ...     21                     0   \n",
       "5     A  BEAUTY MATURE  Face Cleansing  ...     21                     0   \n",
       "6     A  BEAUTY MATURE  Face Cleansing  ...     21                     0   \n",
       "7     A  BEAUTY MATURE  Face Cleansing  ...     21                     0   \n",
       "8     A  BEAUTY MATURE  Face Cleansing  ...     21                     0   \n",
       "9     A  BEAUTY MATURE  Face Cleansing  ...     21                     0   \n",
       "\n",
       "   [Brand] Delay Factor  [SKU] Promo Factor [SKU] Delay Factor  \\\n",
       "0                     0                   0                  0   \n",
       "1                     0                   0                  0   \n",
       "2                     0                   0                  0   \n",
       "3                     0                   0                  0   \n",
       "4                     0                   0                  0   \n",
       "5                     0                  50                  0   \n",
       "6                     0                  50                  0   \n",
       "7                     0                  50                  0   \n",
       "8                     0                   0                  0   \n",
       "9                     0                  50                  0   \n",
       "\n",
       "   [Master - SKU] Promo Factor  [Master - SKU] Delay Factor  Stock Cover  \\\n",
       "0                          NaN                          NaN         0.00   \n",
       "1                          NaN                          NaN        51.02   \n",
       "2                          NaN                          NaN        60.71   \n",
       "3                          NaN                          NaN        62.50   \n",
       "4                          NaN                          NaN        31.40   \n",
       "5                        50.00                          NaN        43.80   \n",
       "6                        50.00                          NaN        58.33   \n",
       "7                        50.00                          NaN        39.69   \n",
       "8                          NaN                          NaN        36.67   \n",
       "9                        50.00                          NaN        26.85   \n",
       "\n",
       "   Days to Backup  Qty to Backup  \n",
       "0            4.00           2.96  \n",
       "1            0.00           0.00  \n",
       "2            0.00           0.00  \n",
       "3            0.00           0.00  \n",
       "4            0.00           0.00  \n",
       "5            0.00           0.00  \n",
       "6            0.00           0.00  \n",
       "7            0.00           0.00  \n",
       "8            0.00           0.00  \n",
       "9            0.00           0.00  \n",
       "\n",
       "[10 rows x 39 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing 1. Miss glam Padang.csv...\n",
      "  - Extracted location: PADANG\n",
      "Processing store: PADANG - 100.0%\n",
      "Merging with suppliers...\n",
      "Found 139 rows without direct store match. Attempting fallback...\n",
      "File saved to /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_1. Miss glam Padang.csv\n",
      "File M2 format saved to /Users/andresuchitra/dev/missglam/autopo/output/m2/m2_1. Miss glam Padang.csv\n",
      "File emergency po saved to /Users/andresuchitra/dev/missglam/autopo/output/emergency/1. Miss glam Padang.csv\n",
      "  - Location: PADANG\n",
      "  - Contribution: 100%\n",
      "  - Rows processed: 6771\n",
      "  - 'Miss Glam Padang' suppliers: 6632 rows\n",
      "  - Other suppliers: 17 rows\n",
      "  - No supplier data: 122 rows\n",
      "  - Saved to: /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_1. Miss glam Padang.csv\n",
      "\n",
      "Processing 10. Miss glam Palembang.csv...\n",
      "  - Extracted location: PALEMBANG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:656: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n",
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:672: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing store: PALEMBANG - 26.0%\n",
      "Overriding with Padang sales data...\n",
      "Merging with suppliers...\n",
      "Found 116 rows without direct store match. Attempting fallback...\n",
      "File saved to /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_10. Miss glam Palembang.csv\n",
      "File M2 format saved to /Users/andresuchitra/dev/missglam/autopo/output/m2/m2_10. Miss glam Palembang.csv\n",
      "File emergency po saved to /Users/andresuchitra/dev/missglam/autopo/output/emergency/10. Miss glam Palembang.csv\n",
      "  - Location: PALEMBANG\n",
      "  - Contribution: 26%\n",
      "  - Rows processed: 4886\n",
      "  - 'Miss Glam Padang' suppliers: 10 rows\n",
      "  - Other suppliers: 4809 rows\n",
      "  - No supplier data: 67 rows\n",
      "  - Saved to: /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_10. Miss glam Palembang.csv\n",
      "\n",
      "Processing 11. Miss glam Damar.csv...\n",
      "  - Extracted location: DAMAR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:656: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n",
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:672: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing store: DAMAR - 91.0%\n",
      "Overriding with Padang sales data...\n",
      "Merging with suppliers...\n",
      "Found 133 rows without direct store match. Attempting fallback...\n",
      "File saved to /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_11. Miss glam Damar.csv\n",
      "File M2 format saved to /Users/andresuchitra/dev/missglam/autopo/output/m2/m2_11. Miss glam Damar.csv\n",
      "File emergency po saved to /Users/andresuchitra/dev/missglam/autopo/output/emergency/11. Miss glam Damar.csv\n",
      "  - Location: DAMAR\n",
      "  - Contribution: 91%\n",
      "  - Rows processed: 6663\n",
      "  - 'Miss Glam Padang' suppliers: 0 rows\n",
      "  - Other suppliers: 6539 rows\n",
      "  - No supplier data: 124 rows\n",
      "  - Saved to: /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_11. Miss glam Damar.csv\n",
      "\n",
      "Processing 12. Miss glam Bangka.csv...\n",
      "  - Extracted location: BANGKA\n",
      "Processing store: BANGKA - 28.0%\n",
      "Overriding with Padang sales data...\n",
      "Merging with suppliers...\n",
      "Found 129 rows without direct store match. Attempting fallback...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:656: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n",
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:672: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_12. Miss glam Bangka.csv\n",
      "File M2 format saved to /Users/andresuchitra/dev/missglam/autopo/output/m2/m2_12. Miss glam Bangka.csv\n",
      "File emergency po saved to /Users/andresuchitra/dev/missglam/autopo/output/emergency/12. Miss glam Bangka.csv\n",
      "  - Location: BANGKA\n",
      "  - Contribution: 28%\n",
      "  - Rows processed: 4546\n",
      "  - 'Miss Glam Padang' suppliers: 21 rows\n",
      "  - Other suppliers: 4447 rows\n",
      "  - No supplier data: 78 rows\n",
      "  - Saved to: /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_12. Miss glam Bangka.csv\n",
      "\n",
      "Processing 13. Miss glam Payakumbuh.csv...\n",
      "  - Extracted location: PAYAKUMBUH\n",
      "Processing store: PAYAKUMBUH - 47.0%\n",
      "Overriding with Padang sales data...\n",
      "Merging with suppliers...\n",
      "Found 84 rows without direct store match. Attempting fallback...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:656: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n",
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:672: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_13. Miss glam Payakumbuh.csv\n",
      "File M2 format saved to /Users/andresuchitra/dev/missglam/autopo/output/m2/m2_13. Miss glam Payakumbuh.csv\n",
      "File emergency po saved to /Users/andresuchitra/dev/missglam/autopo/output/emergency/13. Miss glam Payakumbuh.csv\n",
      "  - Location: PAYAKUMBUH\n",
      "  - Contribution: 47%\n",
      "  - Rows processed: 5314\n",
      "  - 'Miss Glam Padang' suppliers: 0 rows\n",
      "  - Other suppliers: 5233 rows\n",
      "  - No supplier data: 81 rows\n",
      "  - Saved to: /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_13. Miss glam Payakumbuh.csv\n",
      "\n",
      "Processing 14. Miss glam Solok.csv...\n",
      "  - Extracted location: SOLOK\n",
      "Processing store: SOLOK - 37.0%\n",
      "Overriding with Padang sales data...\n",
      "Merging with suppliers...\n",
      "Found 65 rows without direct store match. Attempting fallback...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:656: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n",
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:672: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_14. Miss glam Solok.csv\n",
      "File M2 format saved to /Users/andresuchitra/dev/missglam/autopo/output/m2/m2_14. Miss glam Solok.csv\n",
      "File emergency po saved to /Users/andresuchitra/dev/missglam/autopo/output/emergency/14. Miss glam Solok.csv\n",
      "  - Location: SOLOK\n",
      "  - Contribution: 37%\n",
      "  - Rows processed: 4660\n",
      "  - 'Miss Glam Padang' suppliers: 0 rows\n",
      "  - Other suppliers: 4599 rows\n",
      "  - No supplier data: 61 rows\n",
      "  - Saved to: /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_14. Miss glam Solok.csv\n",
      "\n",
      "Processing 15. Miss glam Tembilahan.csv...\n",
      "  - Extracted location: TEMBILAHAN\n",
      "Processing store: TEMBILAHAN - 27.0%\n",
      "Overriding with Padang sales data...\n",
      "Merging with suppliers...\n",
      "Found 81 rows without direct store match. Attempting fallback...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:656: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n",
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:672: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_15. Miss glam Tembilahan.csv\n",
      "File M2 format saved to /Users/andresuchitra/dev/missglam/autopo/output/m2/m2_15. Miss glam Tembilahan.csv\n",
      "File emergency po saved to /Users/andresuchitra/dev/missglam/autopo/output/emergency/15. Miss glam Tembilahan.csv\n",
      "  - Location: TEMBILAHAN\n",
      "  - Contribution: 27%\n",
      "  - Rows processed: 4349\n",
      "  - 'Miss Glam Padang' suppliers: 9 rows\n",
      "  - Other suppliers: 4274 rows\n",
      "  - No supplier data: 66 rows\n",
      "  - Saved to: /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_15. Miss glam Tembilahan.csv\n",
      "\n",
      "Processing 16. Miss glam Lubuk Linggau.csv...\n",
      "  - Extracted location: LUBUK LINGGAU\n",
      "Processing store: LUBUK LINGGAU - 26.0%\n",
      "Overriding with Padang sales data...\n",
      "Merging with suppliers...\n",
      "Found 175 rows without direct store match. Attempting fallback...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:656: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n",
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:672: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_16. Miss glam Lubuk Linggau.csv\n",
      "File M2 format saved to /Users/andresuchitra/dev/missglam/autopo/output/m2/m2_16. Miss glam Lubuk Linggau.csv\n",
      "File emergency po saved to /Users/andresuchitra/dev/missglam/autopo/output/emergency/16. Miss glam Lubuk Linggau.csv\n",
      "  - Location: LUBUK LINGGAU\n",
      "  - Contribution: 26%\n",
      "  - Rows processed: 4418\n",
      "  - 'Miss Glam Padang' suppliers: 7 rows\n",
      "  - Other suppliers: 4353 rows\n",
      "  - No supplier data: 58 rows\n",
      "  - Saved to: /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_16. Miss glam Lubuk Linggau.csv\n",
      "\n",
      "Processing 17. Miss glam Dumai.csv...\n",
      "  - Extracted location: DUMAI\n",
      "Processing store: DUMAI - 36.0%\n",
      "Overriding with Padang sales data...\n",
      "Merging with suppliers...\n",
      "Found 68 rows without direct store match. Attempting fallback...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:656: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n",
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:672: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_17. Miss glam Dumai.csv\n",
      "File M2 format saved to /Users/andresuchitra/dev/missglam/autopo/output/m2/m2_17. Miss glam Dumai.csv\n",
      "File emergency po saved to /Users/andresuchitra/dev/missglam/autopo/output/emergency/17. Miss glam Dumai.csv\n",
      "  - Location: DUMAI\n",
      "  - Contribution: 36%\n",
      "  - Rows processed: 4774\n",
      "  - 'Miss Glam Padang' suppliers: 1 rows\n",
      "  - Other suppliers: 4708 rows\n",
      "  - No supplier data: 65 rows\n",
      "  - Saved to: /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_17. Miss glam Dumai.csv\n",
      "\n",
      "Processing 18. Miss Glam Kedaton.csv...\n",
      "  - Extracted location: KEDATON\n",
      "Processing store: KEDATON - 18.0%\n",
      "Overriding with Padang sales data...\n",
      "Merging with suppliers...\n",
      "Found 119 rows without direct store match. Attempting fallback...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:656: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n",
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:672: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_18. Miss Glam Kedaton.csv\n",
      "File M2 format saved to /Users/andresuchitra/dev/missglam/autopo/output/m2/m2_18. Miss Glam Kedaton.csv\n",
      "File emergency po saved to /Users/andresuchitra/dev/missglam/autopo/output/emergency/18. Miss Glam Kedaton.csv\n",
      "  - Location: KEDATON\n",
      "  - Contribution: 18%\n",
      "  - Rows processed: 4225\n",
      "  - 'Miss Glam Padang' suppliers: 14 rows\n",
      "  - Other suppliers: 4144 rows\n",
      "  - No supplier data: 67 rows\n",
      "  - Saved to: /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_18. Miss Glam Kedaton.csv\n",
      "\n",
      "Processing 19. Miss Glam Rantau Prapat.csv...\n",
      "  - Extracted location: RANTAU PRAPAT\n",
      "Processing store: RANTAU PRAPAT - 27.0%\n",
      "Overriding with Padang sales data...\n",
      "Merging with suppliers...\n",
      "Found 98 rows without direct store match. Attempting fallback...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:656: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n",
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:672: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_19. Miss Glam Rantau Prapat.csv\n",
      "File M2 format saved to /Users/andresuchitra/dev/missglam/autopo/output/m2/m2_19. Miss Glam Rantau Prapat.csv\n",
      "File emergency po saved to /Users/andresuchitra/dev/missglam/autopo/output/emergency/19. Miss Glam Rantau Prapat.csv\n",
      "  - Location: RANTAU PRAPAT\n",
      "  - Contribution: 27%\n",
      "  - Rows processed: 4287\n",
      "  - 'Miss Glam Padang' suppliers: 19 rows\n",
      "  - Other suppliers: 4200 rows\n",
      "  - No supplier data: 68 rows\n",
      "  - Saved to: /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_19. Miss Glam Rantau Prapat.csv\n",
      "\n",
      "Processing 2. Miss glam Pekanbaru.csv...\n",
      "  - Extracted location: PEKANBARU\n",
      "Processing store: PEKANBARU - 60.0%\n",
      "Overriding with Padang sales data...\n",
      "Merging with suppliers...\n",
      "Found 118 rows without direct store match. Attempting fallback...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:656: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n",
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:672: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_2. Miss glam Pekanbaru.csv\n",
      "File M2 format saved to /Users/andresuchitra/dev/missglam/autopo/output/m2/m2_2. Miss glam Pekanbaru.csv\n",
      "File emergency po saved to /Users/andresuchitra/dev/missglam/autopo/output/emergency/2. Miss glam Pekanbaru.csv\n",
      "  - Location: PEKANBARU\n",
      "  - Contribution: 60%\n",
      "  - Rows processed: 5955\n",
      "  - 'Miss Glam Padang' suppliers: 4 rows\n",
      "  - Other suppliers: 5847 rows\n",
      "  - No supplier data: 104 rows\n",
      "  - Saved to: /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_2. Miss glam Pekanbaru.csv\n",
      "\n",
      "Processing 20. Miss Glam Tanjung Pinang.csv...\n",
      "  - Extracted location: TANJUNG PINANG\n",
      "Processing store: TANJUNG PINANG - 19.0%\n",
      "Overriding with Padang sales data...\n",
      "Merging with suppliers...\n",
      "Found 96 rows without direct store match. Attempting fallback...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:656: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n",
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:672: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_20. Miss Glam Tanjung Pinang.csv\n",
      "File M2 format saved to /Users/andresuchitra/dev/missglam/autopo/output/m2/m2_20. Miss Glam Tanjung Pinang.csv\n",
      "File emergency po saved to /Users/andresuchitra/dev/missglam/autopo/output/emergency/20. Miss Glam Tanjung Pinang.csv\n",
      "  - Location: TANJUNG PINANG\n",
      "  - Contribution: 19%\n",
      "  - Rows processed: 4050\n",
      "  - 'Miss Glam Padang' suppliers: 8 rows\n",
      "  - Other suppliers: 3973 rows\n",
      "  - No supplier data: 69 rows\n",
      "  - Saved to: /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_20. Miss Glam Tanjung Pinang.csv\n",
      "\n",
      "Processing 21. Miss Glam Sutomo.csv...\n",
      "  - Extracted location: SUTOMO\n",
      "Processing store: SUTOMO - 49.0%\n",
      "Overriding with Padang sales data...\n",
      "Merging with suppliers...\n",
      "Found 88 rows without direct store match. Attempting fallback...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:656: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n",
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:672: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_21. Miss Glam Sutomo.csv\n",
      "File M2 format saved to /Users/andresuchitra/dev/missglam/autopo/output/m2/m2_21. Miss Glam Sutomo.csv\n",
      "File emergency po saved to /Users/andresuchitra/dev/missglam/autopo/output/emergency/21. Miss Glam Sutomo.csv\n",
      "  - Location: SUTOMO\n",
      "  - Contribution: 49%\n",
      "  - Rows processed: 5706\n",
      "  - 'Miss Glam Padang' suppliers: 4 rows\n",
      "  - Other suppliers: 5627 rows\n",
      "  - No supplier data: 75 rows\n",
      "  - Saved to: /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_21. Miss Glam Sutomo.csv\n",
      "\n",
      "Processing 22. Miss Glam Pasaman Barat.csv...\n",
      "  - Extracted location: PASAMAN BARAT\n",
      "Processing store: PASAMAN BARAT - 17.0%\n",
      "Overriding with Padang sales data...\n",
      "Merging with suppliers...\n",
      "Found 61 rows without direct store match. Attempting fallback...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:656: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n",
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:672: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_22. Miss Glam Pasaman Barat.csv\n",
      "File M2 format saved to /Users/andresuchitra/dev/missglam/autopo/output/m2/m2_22. Miss Glam Pasaman Barat.csv\n",
      "File emergency po saved to /Users/andresuchitra/dev/missglam/autopo/output/emergency/22. Miss Glam Pasaman Barat.csv\n",
      "  - Location: PASAMAN BARAT\n",
      "  - Contribution: 17%\n",
      "  - Rows processed: 3856\n",
      "  - 'Miss Glam Padang' suppliers: 6 rows\n",
      "  - Other suppliers: 3808 rows\n",
      "  - No supplier data: 42 rows\n",
      "  - Saved to: /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_22. Miss Glam Pasaman Barat.csv\n",
      "\n",
      "Processing 23. Miss Glam Halat.csv...\n",
      "  - Extracted location: HALAT\n",
      "Processing store: HALAT - 31.0%\n",
      "Overriding with Padang sales data...\n",
      "Merging with suppliers...\n",
      "Found 123 rows without direct store match. Attempting fallback...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:656: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n",
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:672: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_23. Miss Glam Halat.csv\n",
      "File M2 format saved to /Users/andresuchitra/dev/missglam/autopo/output/m2/m2_23. Miss Glam Halat.csv\n",
      "File emergency po saved to /Users/andresuchitra/dev/missglam/autopo/output/emergency/23. Miss Glam Halat.csv\n",
      "  - Location: HALAT\n",
      "  - Contribution: 31%\n",
      "  - Rows processed: 4806\n",
      "  - 'Miss Glam Padang' suppliers: 15 rows\n",
      "  - Other suppliers: 4695 rows\n",
      "  - No supplier data: 96 rows\n",
      "  - Saved to: /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_23. Miss Glam Halat.csv\n",
      "\n",
      "Processing 24. Miss Glam Duri.csv...\n",
      "  - Extracted location: DURI\n",
      "Processing store: DURI - 28.0%\n",
      "Overriding with Padang sales data...\n",
      "Merging with suppliers...\n",
      "Found 57 rows without direct store match. Attempting fallback...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:656: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n",
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:672: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_24. Miss Glam Duri.csv\n",
      "File M2 format saved to /Users/andresuchitra/dev/missglam/autopo/output/m2/m2_24. Miss Glam Duri.csv\n",
      "File emergency po saved to /Users/andresuchitra/dev/missglam/autopo/output/emergency/24. Miss Glam Duri.csv\n",
      "  - Location: DURI\n",
      "  - Contribution: 28%\n",
      "  - Rows processed: 3967\n",
      "  - 'Miss Glam Padang' suppliers: 2 rows\n",
      "  - Other suppliers: 3913 rows\n",
      "  - No supplier data: 52 rows\n",
      "  - Saved to: /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_24. Miss Glam Duri.csv\n",
      "\n",
      "Processing 25. Miss Glam Sudirman.csv...\n",
      "  - Extracted location: SUDIRMAN\n",
      "Processing store: SUDIRMAN - 44.0%\n",
      "Overriding with Padang sales data...\n",
      "Merging with suppliers...\n",
      "Found 115 rows without direct store match. Attempting fallback...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:656: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n",
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:672: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_25. Miss Glam Sudirman.csv\n",
      "File M2 format saved to /Users/andresuchitra/dev/missglam/autopo/output/m2/m2_25. Miss Glam Sudirman.csv\n",
      "File emergency po saved to /Users/andresuchitra/dev/missglam/autopo/output/emergency/25. Miss Glam Sudirman.csv\n",
      "  - Location: SUDIRMAN\n",
      "  - Contribution: 44%\n",
      "  - Rows processed: 5630\n",
      "  - 'Miss Glam Padang' suppliers: 4 rows\n",
      "  - Other suppliers: 5526 rows\n",
      "  - No supplier data: 100 rows\n",
      "  - Saved to: /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_25. Miss Glam Sudirman.csv\n",
      "\n",
      "Processing 26. Miss Glam Mansyur .csv...\n",
      "  - Extracted location: MANSYUR\n",
      "Processing store: MANSYUR - 25.0%\n",
      "Overriding with Padang sales data...\n",
      "Merging with suppliers...\n",
      "Found 124 rows without direct store match. Attempting fallback...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:656: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n",
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:672: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_26. Miss Glam Mansyur .csv\n",
      "File M2 format saved to /Users/andresuchitra/dev/missglam/autopo/output/m2/m2_26. Miss Glam Mansyur .csv\n",
      "File emergency po saved to /Users/andresuchitra/dev/missglam/autopo/output/emergency/26. Miss Glam Mansyur .csv\n",
      "  - Location: MANSYUR\n",
      "  - Contribution: 25%\n",
      "  - Rows processed: 4971\n",
      "  - 'Miss Glam Padang' suppliers: 16 rows\n",
      "  - Other suppliers: 4869 rows\n",
      "  - No supplier data: 86 rows\n",
      "  - Saved to: /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_26. Miss Glam Mansyur .csv\n",
      "\n",
      "Processing 27. Miss Glam Padang Sidimpuan.csv...\n",
      "  - Extracted location: PADANG SIDIMPUAN\n",
      "Processing store: PADANG SIDIMPUAN - 31.0%\n",
      "Overriding with Padang sales data...\n",
      "Merging with suppliers...\n",
      "Found 46 rows without direct store match. Attempting fallback...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:656: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n",
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:672: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_27. Miss Glam Padang Sidimpuan.csv\n",
      "File M2 format saved to /Users/andresuchitra/dev/missglam/autopo/output/m2/m2_27. Miss Glam Padang Sidimpuan.csv\n",
      "File emergency po saved to /Users/andresuchitra/dev/missglam/autopo/output/emergency/27. Miss Glam Padang Sidimpuan.csv\n",
      "  - Location: PADANG SIDIMPUAN\n",
      "  - Contribution: 31%\n",
      "  - Rows processed: 3781\n",
      "  - 'Miss Glam Padang' suppliers: 5 rows\n",
      "  - Other suppliers: 3739 rows\n",
      "  - No supplier data: 37 rows\n",
      "  - Saved to: /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_27. Miss Glam Padang Sidimpuan.csv\n",
      "\n",
      "Processing 28. Miss Glam Aceh.csv...\n",
      "  - Extracted location: ACEH\n",
      "Processing store: ACEH - 15.0%\n",
      "Overriding with Padang sales data...\n",
      "Merging with suppliers...\n",
      "Found 72 rows without direct store match. Attempting fallback...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:656: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n",
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:672: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_28. Miss Glam Aceh.csv\n",
      "File M2 format saved to /Users/andresuchitra/dev/missglam/autopo/output/m2/m2_28. Miss Glam Aceh.csv\n",
      "File emergency po saved to /Users/andresuchitra/dev/missglam/autopo/output/emergency/28. Miss Glam Aceh.csv\n",
      "  - Location: ACEH\n",
      "  - Contribution: 15%\n",
      "  - Rows processed: 3561\n",
      "  - 'Miss Glam Padang' suppliers: 14 rows\n",
      "  - Other suppliers: 3502 rows\n",
      "  - No supplier data: 45 rows\n",
      "  - Saved to: /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_28. Miss Glam Aceh.csv\n",
      "\n",
      "Processing 29. Miss Glam Marpoyan.csv...\n",
      "  - Extracted location: MARPOYAN\n",
      "Processing store: MARPOYAN - 30.0%\n",
      "Overriding with Padang sales data...\n",
      "Merging with suppliers...\n",
      "Found 111 rows without direct store match. Attempting fallback...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:656: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n",
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:672: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_29. Miss Glam Marpoyan.csv\n",
      "File M2 format saved to /Users/andresuchitra/dev/missglam/autopo/output/m2/m2_29. Miss Glam Marpoyan.csv\n",
      "File emergency po saved to /Users/andresuchitra/dev/missglam/autopo/output/emergency/29. Miss Glam Marpoyan.csv\n",
      "  - Location: MARPOYAN\n",
      "  - Contribution: 30%\n",
      "  - Rows processed: 4612\n",
      "  - 'Miss Glam Padang' suppliers: 20 rows\n",
      "  - Other suppliers: 4527 rows\n",
      "  - No supplier data: 65 rows\n",
      "  - Saved to: /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_29. Miss Glam Marpoyan.csv\n",
      "\n",
      "Processing 3. Miss glam Jambi.csv...\n",
      "  - Extracted location: JAMBI\n",
      "Processing store: JAMBI - 33.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:656: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n",
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:672: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding with Padang sales data...\n",
      "Merging with suppliers...\n",
      "Found 130 rows without direct store match. Attempting fallback...\n",
      "File saved to /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_3. Miss glam Jambi.csv\n",
      "File M2 format saved to /Users/andresuchitra/dev/missglam/autopo/output/m2/m2_3. Miss glam Jambi.csv\n",
      "File emergency po saved to /Users/andresuchitra/dev/missglam/autopo/output/emergency/3. Miss glam Jambi.csv\n",
      "  - Location: JAMBI\n",
      "  - Contribution: 33%\n",
      "  - Rows processed: 5236\n",
      "  - 'Miss Glam Padang' suppliers: 4 rows\n",
      "  - Other suppliers: 5146 rows\n",
      "  - No supplier data: 86 rows\n",
      "  - Saved to: /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_3. Miss glam Jambi.csv\n",
      "\n",
      "Processing 30. Miss Glam Sei Penuh.csv...\n",
      "  - Extracted location: SEI PENUH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:656: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n",
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:672: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing store: SEI PENUH - 21.0%\n",
      "Overriding with Padang sales data...\n",
      "Merging with suppliers...\n",
      "Found 72 rows without direct store match. Attempting fallback...\n",
      "File saved to /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_30. Miss Glam Sei Penuh.csv\n",
      "File M2 format saved to /Users/andresuchitra/dev/missglam/autopo/output/m2/m2_30. Miss Glam Sei Penuh.csv\n",
      "File emergency po saved to /Users/andresuchitra/dev/missglam/autopo/output/emergency/30. Miss Glam Sei Penuh.csv\n",
      "  - Location: SEI PENUH\n",
      "  - Contribution: 21%\n",
      "  - Rows processed: 3587\n",
      "  - 'Miss Glam Padang' suppliers: 27 rows\n",
      "  - Other suppliers: 3532 rows\n",
      "  - No supplier data: 28 rows\n",
      "  - Saved to: /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_30. Miss Glam Sei Penuh.csv\n",
      "\n",
      "Processing 31. Miss Glam Mayang.csv...\n",
      "  - Extracted location: MAYANG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:656: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n",
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:672: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing store: MAYANG - 18.0%\n",
      "Overriding with Padang sales data...\n",
      "Merging with suppliers...\n",
      "Found 235 rows without direct store match. Attempting fallback...\n",
      "File saved to /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_31. Miss Glam Mayang.csv\n",
      "File M2 format saved to /Users/andresuchitra/dev/missglam/autopo/output/m2/m2_31. Miss Glam Mayang.csv\n",
      "File emergency po saved to /Users/andresuchitra/dev/missglam/autopo/output/emergency/31. Miss Glam Mayang.csv\n",
      "  - Location: MAYANG\n",
      "  - Contribution: 18%\n",
      "  - Rows processed: 4257\n",
      "  - 'Miss Glam Padang' suppliers: 30 rows\n",
      "  - Other suppliers: 4180 rows\n",
      "  - No supplier data: 47 rows\n",
      "  - Saved to: /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_31. Miss Glam Mayang.csv\n",
      "\n",
      "Processing 32. Miss Glam Soeta.csv...\n",
      "  - Extracted location: SOETA\n",
      "Warning: No contribution percentage found for SOETA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:656: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n",
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:672: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing store: SOETA - 100.0%\n",
      "Merging with suppliers...\n",
      "Found 2011 rows without direct store match. Attempting fallback...\n",
      "File saved to /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_32. Miss Glam Soeta.csv\n",
      "File M2 format saved to /Users/andresuchitra/dev/missglam/autopo/output/m2/m2_32. Miss Glam Soeta.csv\n",
      "File emergency po saved to /Users/andresuchitra/dev/missglam/autopo/output/emergency/32. Miss Glam Soeta.csv\n",
      "  - Location: SOETA\n",
      "  - Contribution: 100%\n",
      "  - Rows processed: 4483\n",
      "  - 'Miss Glam Padang' suppliers: 124 rows\n",
      "  - Other suppliers: 4319 rows\n",
      "  - No supplier data: 40 rows\n",
      "  - Saved to: /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_32. Miss Glam Soeta.csv\n",
      "\n",
      "Processing 33. Miss Glam Balikpapan.csv...\n",
      "  - Extracted location: BALIKPAPAN\n",
      "Warning: No contribution percentage found for BALIKPAPAN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:656: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n",
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:672: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing store: BALIKPAPAN - 100.0%\n",
      "Merging with suppliers...\n",
      "Found 1584 rows without direct store match. Attempting fallback...\n",
      "File saved to /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_33. Miss Glam Balikpapan.csv\n",
      "File M2 format saved to /Users/andresuchitra/dev/missglam/autopo/output/m2/m2_33. Miss Glam Balikpapan.csv\n",
      "File emergency po saved to /Users/andresuchitra/dev/missglam/autopo/output/emergency/33. Miss Glam Balikpapan.csv\n",
      "  - Location: BALIKPAPAN\n",
      "  - Contribution: 100%\n",
      "  - Rows processed: 4468\n",
      "  - 'Miss Glam Padang' suppliers: 84 rows\n",
      "  - Other suppliers: 4323 rows\n",
      "  - No supplier data: 61 rows\n",
      "  - Saved to: /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_33. Miss Glam Balikpapan.csv\n",
      "\n",
      "Processing 4. Miss glam Bukittinggi.csv...\n",
      "  - Extracted location: BUKITTINGGI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:656: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n",
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:672: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing store: BUKITTINGGI - 45.0%\n",
      "Overriding with Padang sales data...\n",
      "Merging with suppliers...\n",
      "Found 71 rows without direct store match. Attempting fallback...\n",
      "File saved to /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_4. Miss glam Bukittinggi.csv\n",
      "File M2 format saved to /Users/andresuchitra/dev/missglam/autopo/output/m2/m2_4. Miss glam Bukittinggi.csv\n",
      "File emergency po saved to /Users/andresuchitra/dev/missglam/autopo/output/emergency/4. Miss glam Bukittinggi.csv\n",
      "  - Location: BUKITTINGGI\n",
      "  - Contribution: 45%\n",
      "  - Rows processed: 5332\n",
      "  - 'Miss Glam Padang' suppliers: 1 rows\n",
      "  - Other suppliers: 5267 rows\n",
      "  - No supplier data: 64 rows\n",
      "  - Saved to: /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_4. Miss glam Bukittinggi.csv\n",
      "\n",
      "Processing 5. Miss glam Panam.csv...\n",
      "  - Extracted location: PANAM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:656: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n",
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:672: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing store: PANAM - 46.0%\n",
      "Overriding with Padang sales data...\n",
      "Merging with suppliers...\n",
      "Found 101 rows without direct store match. Attempting fallback...\n",
      "File saved to /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_5. Miss glam Panam.csv\n",
      "File M2 format saved to /Users/andresuchitra/dev/missglam/autopo/output/m2/m2_5. Miss glam Panam.csv\n",
      "File emergency po saved to /Users/andresuchitra/dev/missglam/autopo/output/emergency/5. Miss glam Panam.csv\n",
      "  - Location: PANAM\n",
      "  - Contribution: 46%\n",
      "  - Rows processed: 5271\n",
      "  - 'Miss Glam Padang' suppliers: 0 rows\n",
      "  - Other suppliers: 5174 rows\n",
      "  - No supplier data: 97 rows\n",
      "  - Saved to: /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_5. Miss glam Panam.csv\n",
      "\n",
      "Processing 6. Miss glam Muaro bungo.csv...\n",
      "  - Extracted location: MUARO BUNGO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:656: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n",
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:672: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing store: MUARO BUNGO - 42.0%\n",
      "Overriding with Padang sales data...\n",
      "Merging with suppliers...\n",
      "Found 96 rows without direct store match. Attempting fallback...\n",
      "File saved to /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_6. Miss glam Muaro bungo.csv\n",
      "File M2 format saved to /Users/andresuchitra/dev/missglam/autopo/output/m2/m2_6. Miss glam Muaro bungo.csv\n",
      "File emergency po saved to /Users/andresuchitra/dev/missglam/autopo/output/emergency/6. Miss glam Muaro bungo.csv\n",
      "  - Location: MUARO BUNGO\n",
      "  - Contribution: 42%\n",
      "  - Rows processed: 4910\n",
      "  - 'Miss Glam Padang' suppliers: 7 rows\n",
      "  - Other suppliers: 4834 rows\n",
      "  - No supplier data: 69 rows\n",
      "  - Saved to: /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_6. Miss glam Muaro bungo.csv\n",
      "\n",
      "Processing 7. Miss glam Lampung.csv...\n",
      "  - Extracted location: LAMPUNG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:656: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n",
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:672: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing store: LAMPUNG - 18.0%\n",
      "Overriding with Padang sales data...\n",
      "Merging with suppliers...\n",
      "Found 106 rows without direct store match. Attempting fallback...\n",
      "File saved to /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_7. Miss glam Lampung.csv\n",
      "File M2 format saved to /Users/andresuchitra/dev/missglam/autopo/output/m2/m2_7. Miss glam Lampung.csv\n",
      "File emergency po saved to /Users/andresuchitra/dev/missglam/autopo/output/emergency/7. Miss glam Lampung.csv\n",
      "  - Location: LAMPUNG\n",
      "  - Contribution: 18%\n",
      "  - Rows processed: 4431\n",
      "  - 'Miss Glam Padang' suppliers: 17 rows\n",
      "  - Other suppliers: 4352 rows\n",
      "  - No supplier data: 62 rows\n",
      "  - Saved to: /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_7. Miss glam Lampung.csv\n",
      "\n",
      "Processing 8. Miss glam Bengkulu.csv...\n",
      "  - Extracted location: BENGKULU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:656: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n",
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:672: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing store: BENGKULU - 14.0%\n",
      "Overriding with Padang sales data...\n",
      "Merging with suppliers...\n",
      "Found 108 rows without direct store match. Attempting fallback...\n",
      "File saved to /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_8. Miss glam Bengkulu.csv\n",
      "File M2 format saved to /Users/andresuchitra/dev/missglam/autopo/output/m2/m2_8. Miss glam Bengkulu.csv\n",
      "File emergency po saved to /Users/andresuchitra/dev/missglam/autopo/output/emergency/8. Miss glam Bengkulu.csv\n",
      "  - Location: BENGKULU\n",
      "  - Contribution: 14%\n",
      "  - Rows processed: 3959\n",
      "  - 'Miss Glam Padang' suppliers: 14 rows\n",
      "  - Other suppliers: 3873 rows\n",
      "  - No supplier data: 72 rows\n",
      "  - Saved to: /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_8. Miss glam Bengkulu.csv\n",
      "\n",
      "Processing 9. Miss glam Medan.csv...\n",
      "  - Extracted location: MEDAN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:656: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n",
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:672: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing store: MEDAN - 46.0%\n",
      "Overriding with Padang sales data...\n",
      "Merging with suppliers...\n",
      "Found 153 rows without direct store match. Attempting fallback...\n",
      "File saved to /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_9. Miss glam Medan.csv\n",
      "File M2 format saved to /Users/andresuchitra/dev/missglam/autopo/output/m2/m2_9. Miss glam Medan.csv\n",
      "File emergency po saved to /Users/andresuchitra/dev/missglam/autopo/output/emergency/9. Miss glam Medan.csv\n",
      "  - Location: MEDAN\n",
      "  - Contribution: 46%\n",
      "  - Rows processed: 5770\n",
      "  - 'Miss Glam Padang' suppliers: 14 rows\n",
      "  - Other suppliers: 5645 rows\n",
      "  - No supplier data: 111 rows\n",
      "  - Saved to: /Users/andresuchitra/dev/missglam/autopo/output/complete/with_suppliers_9. Miss glam Medan.csv\n",
      "\n",
      "Processing complete! Summary:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:656: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n",
      "/var/folders/8t/7219xcjd2dj829bf02_x9zy80000gn/T/ipykernel_59618/3187934781.py:672: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>location</th>\n",
       "      <th>contribution_pct</th>\n",
       "      <th>total_rows</th>\n",
       "      <th>padang_suppliers</th>\n",
       "      <th>other_suppliers</th>\n",
       "      <th>no_supplier</th>\n",
       "      <th>status</th>\n",
       "      <th>output_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. Miss glam Padang.csv</td>\n",
       "      <td>PADANG</td>\n",
       "      <td>100</td>\n",
       "      <td>6771</td>\n",
       "      <td>6632</td>\n",
       "      <td>17</td>\n",
       "      <td>122</td>\n",
       "      <td>Success</td>\n",
       "      <td>/Users/andresuchitra/dev/missglam/autopo/outpu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10. Miss glam Palembang.csv</td>\n",
       "      <td>PALEMBANG</td>\n",
       "      <td>26</td>\n",
       "      <td>4886</td>\n",
       "      <td>10</td>\n",
       "      <td>4809</td>\n",
       "      <td>67</td>\n",
       "      <td>Success</td>\n",
       "      <td>/Users/andresuchitra/dev/missglam/autopo/outpu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11. Miss glam Damar.csv</td>\n",
       "      <td>DAMAR</td>\n",
       "      <td>91</td>\n",
       "      <td>6663</td>\n",
       "      <td>0</td>\n",
       "      <td>6539</td>\n",
       "      <td>124</td>\n",
       "      <td>Success</td>\n",
       "      <td>/Users/andresuchitra/dev/missglam/autopo/outpu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12. Miss glam Bangka.csv</td>\n",
       "      <td>BANGKA</td>\n",
       "      <td>28</td>\n",
       "      <td>4546</td>\n",
       "      <td>21</td>\n",
       "      <td>4447</td>\n",
       "      <td>78</td>\n",
       "      <td>Success</td>\n",
       "      <td>/Users/andresuchitra/dev/missglam/autopo/outpu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13. Miss glam Payakumbuh.csv</td>\n",
       "      <td>PAYAKUMBUH</td>\n",
       "      <td>47</td>\n",
       "      <td>5314</td>\n",
       "      <td>0</td>\n",
       "      <td>5233</td>\n",
       "      <td>81</td>\n",
       "      <td>Success</td>\n",
       "      <td>/Users/andresuchitra/dev/missglam/autopo/outpu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14. Miss glam Solok.csv</td>\n",
       "      <td>SOLOK</td>\n",
       "      <td>37</td>\n",
       "      <td>4660</td>\n",
       "      <td>0</td>\n",
       "      <td>4599</td>\n",
       "      <td>61</td>\n",
       "      <td>Success</td>\n",
       "      <td>/Users/andresuchitra/dev/missglam/autopo/outpu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15. Miss glam Tembilahan.csv</td>\n",
       "      <td>TEMBILAHAN</td>\n",
       "      <td>27</td>\n",
       "      <td>4349</td>\n",
       "      <td>9</td>\n",
       "      <td>4274</td>\n",
       "      <td>66</td>\n",
       "      <td>Success</td>\n",
       "      <td>/Users/andresuchitra/dev/missglam/autopo/outpu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16. Miss glam Lubuk Linggau.csv</td>\n",
       "      <td>LUBUK LINGGAU</td>\n",
       "      <td>26</td>\n",
       "      <td>4418</td>\n",
       "      <td>7</td>\n",
       "      <td>4353</td>\n",
       "      <td>58</td>\n",
       "      <td>Success</td>\n",
       "      <td>/Users/andresuchitra/dev/missglam/autopo/outpu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17. Miss glam Dumai.csv</td>\n",
       "      <td>DUMAI</td>\n",
       "      <td>36</td>\n",
       "      <td>4774</td>\n",
       "      <td>1</td>\n",
       "      <td>4708</td>\n",
       "      <td>65</td>\n",
       "      <td>Success</td>\n",
       "      <td>/Users/andresuchitra/dev/missglam/autopo/outpu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18. Miss Glam Kedaton.csv</td>\n",
       "      <td>KEDATON</td>\n",
       "      <td>18</td>\n",
       "      <td>4225</td>\n",
       "      <td>14</td>\n",
       "      <td>4144</td>\n",
       "      <td>67</td>\n",
       "      <td>Success</td>\n",
       "      <td>/Users/andresuchitra/dev/missglam/autopo/outpu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>19. Miss Glam Rantau Prapat.csv</td>\n",
       "      <td>RANTAU PRAPAT</td>\n",
       "      <td>27</td>\n",
       "      <td>4287</td>\n",
       "      <td>19</td>\n",
       "      <td>4200</td>\n",
       "      <td>68</td>\n",
       "      <td>Success</td>\n",
       "      <td>/Users/andresuchitra/dev/missglam/autopo/outpu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2. Miss glam Pekanbaru.csv</td>\n",
       "      <td>PEKANBARU</td>\n",
       "      <td>60</td>\n",
       "      <td>5955</td>\n",
       "      <td>4</td>\n",
       "      <td>5847</td>\n",
       "      <td>104</td>\n",
       "      <td>Success</td>\n",
       "      <td>/Users/andresuchitra/dev/missglam/autopo/outpu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20. Miss Glam Tanjung Pinang.csv</td>\n",
       "      <td>TANJUNG PINANG</td>\n",
       "      <td>19</td>\n",
       "      <td>4050</td>\n",
       "      <td>8</td>\n",
       "      <td>3973</td>\n",
       "      <td>69</td>\n",
       "      <td>Success</td>\n",
       "      <td>/Users/andresuchitra/dev/missglam/autopo/outpu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>21. Miss Glam Sutomo.csv</td>\n",
       "      <td>SUTOMO</td>\n",
       "      <td>49</td>\n",
       "      <td>5706</td>\n",
       "      <td>4</td>\n",
       "      <td>5627</td>\n",
       "      <td>75</td>\n",
       "      <td>Success</td>\n",
       "      <td>/Users/andresuchitra/dev/missglam/autopo/outpu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>22. Miss Glam Pasaman Barat.csv</td>\n",
       "      <td>PASAMAN BARAT</td>\n",
       "      <td>17</td>\n",
       "      <td>3856</td>\n",
       "      <td>6</td>\n",
       "      <td>3808</td>\n",
       "      <td>42</td>\n",
       "      <td>Success</td>\n",
       "      <td>/Users/andresuchitra/dev/missglam/autopo/outpu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>23. Miss Glam Halat.csv</td>\n",
       "      <td>HALAT</td>\n",
       "      <td>31</td>\n",
       "      <td>4806</td>\n",
       "      <td>15</td>\n",
       "      <td>4695</td>\n",
       "      <td>96</td>\n",
       "      <td>Success</td>\n",
       "      <td>/Users/andresuchitra/dev/missglam/autopo/outpu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>24. Miss Glam Duri.csv</td>\n",
       "      <td>DURI</td>\n",
       "      <td>28</td>\n",
       "      <td>3967</td>\n",
       "      <td>2</td>\n",
       "      <td>3913</td>\n",
       "      <td>52</td>\n",
       "      <td>Success</td>\n",
       "      <td>/Users/andresuchitra/dev/missglam/autopo/outpu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>25. Miss Glam Sudirman.csv</td>\n",
       "      <td>SUDIRMAN</td>\n",
       "      <td>44</td>\n",
       "      <td>5630</td>\n",
       "      <td>4</td>\n",
       "      <td>5526</td>\n",
       "      <td>100</td>\n",
       "      <td>Success</td>\n",
       "      <td>/Users/andresuchitra/dev/missglam/autopo/outpu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>26. Miss Glam Mansyur .csv</td>\n",
       "      <td>MANSYUR</td>\n",
       "      <td>25</td>\n",
       "      <td>4971</td>\n",
       "      <td>16</td>\n",
       "      <td>4869</td>\n",
       "      <td>86</td>\n",
       "      <td>Success</td>\n",
       "      <td>/Users/andresuchitra/dev/missglam/autopo/outpu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>27. Miss Glam Padang Sidimpuan.csv</td>\n",
       "      <td>PADANG SIDIMPUAN</td>\n",
       "      <td>31</td>\n",
       "      <td>3781</td>\n",
       "      <td>5</td>\n",
       "      <td>3739</td>\n",
       "      <td>37</td>\n",
       "      <td>Success</td>\n",
       "      <td>/Users/andresuchitra/dev/missglam/autopo/outpu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>28. Miss Glam Aceh.csv</td>\n",
       "      <td>ACEH</td>\n",
       "      <td>15</td>\n",
       "      <td>3561</td>\n",
       "      <td>14</td>\n",
       "      <td>3502</td>\n",
       "      <td>45</td>\n",
       "      <td>Success</td>\n",
       "      <td>/Users/andresuchitra/dev/missglam/autopo/outpu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>29. Miss Glam Marpoyan.csv</td>\n",
       "      <td>MARPOYAN</td>\n",
       "      <td>30</td>\n",
       "      <td>4612</td>\n",
       "      <td>20</td>\n",
       "      <td>4527</td>\n",
       "      <td>65</td>\n",
       "      <td>Success</td>\n",
       "      <td>/Users/andresuchitra/dev/missglam/autopo/outpu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3. Miss glam Jambi.csv</td>\n",
       "      <td>JAMBI</td>\n",
       "      <td>33</td>\n",
       "      <td>5236</td>\n",
       "      <td>4</td>\n",
       "      <td>5146</td>\n",
       "      <td>86</td>\n",
       "      <td>Success</td>\n",
       "      <td>/Users/andresuchitra/dev/missglam/autopo/outpu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>30. Miss Glam Sei Penuh.csv</td>\n",
       "      <td>SEI PENUH</td>\n",
       "      <td>21</td>\n",
       "      <td>3587</td>\n",
       "      <td>27</td>\n",
       "      <td>3532</td>\n",
       "      <td>28</td>\n",
       "      <td>Success</td>\n",
       "      <td>/Users/andresuchitra/dev/missglam/autopo/outpu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>31. Miss Glam Mayang.csv</td>\n",
       "      <td>MAYANG</td>\n",
       "      <td>18</td>\n",
       "      <td>4257</td>\n",
       "      <td>30</td>\n",
       "      <td>4180</td>\n",
       "      <td>47</td>\n",
       "      <td>Success</td>\n",
       "      <td>/Users/andresuchitra/dev/missglam/autopo/outpu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>32. Miss Glam Soeta.csv</td>\n",
       "      <td>SOETA</td>\n",
       "      <td>100</td>\n",
       "      <td>4483</td>\n",
       "      <td>124</td>\n",
       "      <td>4319</td>\n",
       "      <td>40</td>\n",
       "      <td>Success</td>\n",
       "      <td>/Users/andresuchitra/dev/missglam/autopo/outpu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>33. Miss Glam Balikpapan.csv</td>\n",
       "      <td>BALIKPAPAN</td>\n",
       "      <td>100</td>\n",
       "      <td>4468</td>\n",
       "      <td>84</td>\n",
       "      <td>4323</td>\n",
       "      <td>61</td>\n",
       "      <td>Success</td>\n",
       "      <td>/Users/andresuchitra/dev/missglam/autopo/outpu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4. Miss glam Bukittinggi.csv</td>\n",
       "      <td>BUKITTINGGI</td>\n",
       "      <td>45</td>\n",
       "      <td>5332</td>\n",
       "      <td>1</td>\n",
       "      <td>5267</td>\n",
       "      <td>64</td>\n",
       "      <td>Success</td>\n",
       "      <td>/Users/andresuchitra/dev/missglam/autopo/outpu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5. Miss glam Panam.csv</td>\n",
       "      <td>PANAM</td>\n",
       "      <td>46</td>\n",
       "      <td>5271</td>\n",
       "      <td>0</td>\n",
       "      <td>5174</td>\n",
       "      <td>97</td>\n",
       "      <td>Success</td>\n",
       "      <td>/Users/andresuchitra/dev/missglam/autopo/outpu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>6. Miss glam Muaro bungo.csv</td>\n",
       "      <td>MUARO BUNGO</td>\n",
       "      <td>42</td>\n",
       "      <td>4910</td>\n",
       "      <td>7</td>\n",
       "      <td>4834</td>\n",
       "      <td>69</td>\n",
       "      <td>Success</td>\n",
       "      <td>/Users/andresuchitra/dev/missglam/autopo/outpu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>7. Miss glam Lampung.csv</td>\n",
       "      <td>LAMPUNG</td>\n",
       "      <td>18</td>\n",
       "      <td>4431</td>\n",
       "      <td>17</td>\n",
       "      <td>4352</td>\n",
       "      <td>62</td>\n",
       "      <td>Success</td>\n",
       "      <td>/Users/andresuchitra/dev/missglam/autopo/outpu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>8. Miss glam Bengkulu.csv</td>\n",
       "      <td>BENGKULU</td>\n",
       "      <td>14</td>\n",
       "      <td>3959</td>\n",
       "      <td>14</td>\n",
       "      <td>3873</td>\n",
       "      <td>72</td>\n",
       "      <td>Success</td>\n",
       "      <td>/Users/andresuchitra/dev/missglam/autopo/outpu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>9. Miss glam Medan.csv</td>\n",
       "      <td>MEDAN</td>\n",
       "      <td>46</td>\n",
       "      <td>5770</td>\n",
       "      <td>14</td>\n",
       "      <td>5645</td>\n",
       "      <td>111</td>\n",
       "      <td>Success</td>\n",
       "      <td>/Users/andresuchitra/dev/missglam/autopo/outpu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  file          location contribution_pct  \\\n",
       "0              1. Miss glam Padang.csv            PADANG              100   \n",
       "1          10. Miss glam Palembang.csv         PALEMBANG               26   \n",
       "2              11. Miss glam Damar.csv             DAMAR               91   \n",
       "3             12. Miss glam Bangka.csv            BANGKA               28   \n",
       "4         13. Miss glam Payakumbuh.csv        PAYAKUMBUH               47   \n",
       "5              14. Miss glam Solok.csv             SOLOK               37   \n",
       "6         15. Miss glam Tembilahan.csv        TEMBILAHAN               27   \n",
       "7      16. Miss glam Lubuk Linggau.csv     LUBUK LINGGAU               26   \n",
       "8              17. Miss glam Dumai.csv             DUMAI               36   \n",
       "9            18. Miss Glam Kedaton.csv           KEDATON               18   \n",
       "10     19. Miss Glam Rantau Prapat.csv     RANTAU PRAPAT               27   \n",
       "11          2. Miss glam Pekanbaru.csv         PEKANBARU               60   \n",
       "12    20. Miss Glam Tanjung Pinang.csv    TANJUNG PINANG               19   \n",
       "13            21. Miss Glam Sutomo.csv            SUTOMO               49   \n",
       "14     22. Miss Glam Pasaman Barat.csv     PASAMAN BARAT               17   \n",
       "15             23. Miss Glam Halat.csv             HALAT               31   \n",
       "16              24. Miss Glam Duri.csv              DURI               28   \n",
       "17          25. Miss Glam Sudirman.csv          SUDIRMAN               44   \n",
       "18          26. Miss Glam Mansyur .csv           MANSYUR               25   \n",
       "19  27. Miss Glam Padang Sidimpuan.csv  PADANG SIDIMPUAN               31   \n",
       "20              28. Miss Glam Aceh.csv              ACEH               15   \n",
       "21          29. Miss Glam Marpoyan.csv          MARPOYAN               30   \n",
       "22              3. Miss glam Jambi.csv             JAMBI               33   \n",
       "23         30. Miss Glam Sei Penuh.csv         SEI PENUH               21   \n",
       "24            31. Miss Glam Mayang.csv            MAYANG               18   \n",
       "25             32. Miss Glam Soeta.csv             SOETA              100   \n",
       "26        33. Miss Glam Balikpapan.csv        BALIKPAPAN              100   \n",
       "27        4. Miss glam Bukittinggi.csv       BUKITTINGGI               45   \n",
       "28              5. Miss glam Panam.csv             PANAM               46   \n",
       "29        6. Miss glam Muaro bungo.csv       MUARO BUNGO               42   \n",
       "30            7. Miss glam Lampung.csv           LAMPUNG               18   \n",
       "31           8. Miss glam Bengkulu.csv          BENGKULU               14   \n",
       "32              9. Miss glam Medan.csv             MEDAN               46   \n",
       "\n",
       "    total_rows  padang_suppliers  other_suppliers  no_supplier   status  \\\n",
       "0         6771              6632               17          122  Success   \n",
       "1         4886                10             4809           67  Success   \n",
       "2         6663                 0             6539          124  Success   \n",
       "3         4546                21             4447           78  Success   \n",
       "4         5314                 0             5233           81  Success   \n",
       "5         4660                 0             4599           61  Success   \n",
       "6         4349                 9             4274           66  Success   \n",
       "7         4418                 7             4353           58  Success   \n",
       "8         4774                 1             4708           65  Success   \n",
       "9         4225                14             4144           67  Success   \n",
       "10        4287                19             4200           68  Success   \n",
       "11        5955                 4             5847          104  Success   \n",
       "12        4050                 8             3973           69  Success   \n",
       "13        5706                 4             5627           75  Success   \n",
       "14        3856                 6             3808           42  Success   \n",
       "15        4806                15             4695           96  Success   \n",
       "16        3967                 2             3913           52  Success   \n",
       "17        5630                 4             5526          100  Success   \n",
       "18        4971                16             4869           86  Success   \n",
       "19        3781                 5             3739           37  Success   \n",
       "20        3561                14             3502           45  Success   \n",
       "21        4612                20             4527           65  Success   \n",
       "22        5236                 4             5146           86  Success   \n",
       "23        3587                27             3532           28  Success   \n",
       "24        4257                30             4180           47  Success   \n",
       "25        4483               124             4319           40  Success   \n",
       "26        4468                84             4323           61  Success   \n",
       "27        5332                 1             5267           64  Success   \n",
       "28        5271                 0             5174           97  Success   \n",
       "29        4910                 7             4834           69  Success   \n",
       "30        4431                17             4352           62  Success   \n",
       "31        3959                14             3873           72  Success   \n",
       "32        5770                14             5645          111  Success   \n",
       "\n",
       "                                          output_path  \n",
       "0   /Users/andresuchitra/dev/missglam/autopo/outpu...  \n",
       "1   /Users/andresuchitra/dev/missglam/autopo/outpu...  \n",
       "2   /Users/andresuchitra/dev/missglam/autopo/outpu...  \n",
       "3   /Users/andresuchitra/dev/missglam/autopo/outpu...  \n",
       "4   /Users/andresuchitra/dev/missglam/autopo/outpu...  \n",
       "5   /Users/andresuchitra/dev/missglam/autopo/outpu...  \n",
       "6   /Users/andresuchitra/dev/missglam/autopo/outpu...  \n",
       "7   /Users/andresuchitra/dev/missglam/autopo/outpu...  \n",
       "8   /Users/andresuchitra/dev/missglam/autopo/outpu...  \n",
       "9   /Users/andresuchitra/dev/missglam/autopo/outpu...  \n",
       "10  /Users/andresuchitra/dev/missglam/autopo/outpu...  \n",
       "11  /Users/andresuchitra/dev/missglam/autopo/outpu...  \n",
       "12  /Users/andresuchitra/dev/missglam/autopo/outpu...  \n",
       "13  /Users/andresuchitra/dev/missglam/autopo/outpu...  \n",
       "14  /Users/andresuchitra/dev/missglam/autopo/outpu...  \n",
       "15  /Users/andresuchitra/dev/missglam/autopo/outpu...  \n",
       "16  /Users/andresuchitra/dev/missglam/autopo/outpu...  \n",
       "17  /Users/andresuchitra/dev/missglam/autopo/outpu...  \n",
       "18  /Users/andresuchitra/dev/missglam/autopo/outpu...  \n",
       "19  /Users/andresuchitra/dev/missglam/autopo/outpu...  \n",
       "20  /Users/andresuchitra/dev/missglam/autopo/outpu...  \n",
       "21  /Users/andresuchitra/dev/missglam/autopo/outpu...  \n",
       "22  /Users/andresuchitra/dev/missglam/autopo/outpu...  \n",
       "23  /Users/andresuchitra/dev/missglam/autopo/outpu...  \n",
       "24  /Users/andresuchitra/dev/missglam/autopo/outpu...  \n",
       "25  /Users/andresuchitra/dev/missglam/autopo/outpu...  \n",
       "26  /Users/andresuchitra/dev/missglam/autopo/outpu...  \n",
       "27  /Users/andresuchitra/dev/missglam/autopo/outpu...  \n",
       "28  /Users/andresuchitra/dev/missglam/autopo/outpu...  \n",
       "29  /Users/andresuchitra/dev/missglam/autopo/outpu...  \n",
       "30  /Users/andresuchitra/dev/missglam/autopo/outpu...  \n",
       "31  /Users/andresuchitra/dev/missglam/autopo/outpu...  \n",
       "32  /Users/andresuchitra/dev/missglam/autopo/outpu...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample of the last processed file:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>SKU</th>\n",
       "      <th>Nama</th>\n",
       "      <th>Toko</th>\n",
       "      <th>Stok</th>\n",
       "      <th>Orig Daily Sales</th>\n",
       "      <th>Orig Max. Daily Sales</th>\n",
       "      <th>Lead Time</th>\n",
       "      <th>Max. Lead Time</th>\n",
       "      <th>Min. Order</th>\n",
       "      <th>...</th>\n",
       "      <th>Reorder point</th>\n",
       "      <th>Stock cover 30 days</th>\n",
       "      <th>current_stock_days_cover</th>\n",
       "      <th>is_open_po</th>\n",
       "      <th>initial_qty_po</th>\n",
       "      <th>emergency_po_qty</th>\n",
       "      <th>updated_regular_po_qty</th>\n",
       "      <th>final_updated_regular_po_qty</th>\n",
       "      <th>emergency_po_cost</th>\n",
       "      <th>final_updated_regular_po_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACNAWAY</td>\n",
       "      <td>10400614911</td>\n",
       "      <td>ACNAWAY 3 in 1 Acne Sun Serum Sunscreen Serum ...</td>\n",
       "      <td>Miss Glam Medan</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>28.00</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>200.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACNAWAY</td>\n",
       "      <td>10400517459</td>\n",
       "      <td>ACNAWAY Mugwort Daily Sunscreen Only For Acne ...</td>\n",
       "      <td>Miss Glam Medan</td>\n",
       "      <td>13.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>28.00</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>85</td>\n",
       "      <td>8</td>\n",
       "      <td>52.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACNAWAY</td>\n",
       "      <td>101001107647</td>\n",
       "      <td>ACNAWAY Mugwort Gel Facial Wash Mugwort + Cent...</td>\n",
       "      <td>Miss Glam Medan</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>28.00</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>52</td>\n",
       "      <td>11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACNES</td>\n",
       "      <td>8992821102372</td>\n",
       "      <td>ACNES Complete White Face Wash 100gr</td>\n",
       "      <td>Miss Glam Medan</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>20.22</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>106492.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACNES</td>\n",
       "      <td>8992821102365</td>\n",
       "      <td>ACNES Complete White Face Wash 50gr</td>\n",
       "      <td>Miss Glam Medan</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>29</td>\n",
       "      <td>19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>207662.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5765</th>\n",
       "      <td>YOUVIT</td>\n",
       "      <td>60100406456</td>\n",
       "      <td>YOUVIT Ezzleep 7 Gummies 28gr</td>\n",
       "      <td>Miss Glam Medan</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28428.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5766</th>\n",
       "      <td>YU CHUN</td>\n",
       "      <td>8997014402932</td>\n",
       "      <td>YU CHUN Mei Cordyceps Brightening Cleanser 100ml</td>\n",
       "      <td>Miss Glam Medan</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>86.96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5767</th>\n",
       "      <td>YU CHUN</td>\n",
       "      <td>8997014402703</td>\n",
       "      <td>YU CHUN Mei Cordyceps Lightening Day Cream 30gr</td>\n",
       "      <td>Miss Glam Medan</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>72.46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5768</th>\n",
       "      <td>YU CHUN</td>\n",
       "      <td>8997014402710</td>\n",
       "      <td>YU CHUN Mei Cordyceps Lightening Night Cream 30g</td>\n",
       "      <td>Miss Glam Medan</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>44289.00</td>\n",
       "      <td>132867.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5769</th>\n",
       "      <td>YU CHUN</td>\n",
       "      <td>8997014402918</td>\n",
       "      <td>YU CHUN Mei Serum Whitening Essence 30ml</td>\n",
       "      <td>Miss Glam Medan</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>217.39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5770 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Brand            SKU  \\\n",
       "0     ACNAWAY    10400614911   \n",
       "1     ACNAWAY    10400517459   \n",
       "2     ACNAWAY   101001107647   \n",
       "3       ACNES  8992821102372   \n",
       "4       ACNES  8992821102365   \n",
       "...       ...            ...   \n",
       "5765   YOUVIT    60100406456   \n",
       "5766  YU CHUN  8997014402932   \n",
       "5767  YU CHUN  8997014402703   \n",
       "5768  YU CHUN  8997014402710   \n",
       "5769  YU CHUN  8997014402918   \n",
       "\n",
       "                                                   Nama             Toko  \\\n",
       "0     ACNAWAY 3 in 1 Acne Sun Serum Sunscreen Serum ...  Miss Glam Medan   \n",
       "1     ACNAWAY Mugwort Daily Sunscreen Only For Acne ...  Miss Glam Medan   \n",
       "2     ACNAWAY Mugwort Gel Facial Wash Mugwort + Cent...  Miss Glam Medan   \n",
       "3                  ACNES Complete White Face Wash 100gr  Miss Glam Medan   \n",
       "4                   ACNES Complete White Face Wash 50gr  Miss Glam Medan   \n",
       "...                                                 ...              ...   \n",
       "5765                      YOUVIT Ezzleep 7 Gummies 28gr  Miss Glam Medan   \n",
       "5766   YU CHUN Mei Cordyceps Brightening Cleanser 100ml  Miss Glam Medan   \n",
       "5767    YU CHUN Mei Cordyceps Lightening Day Cream 30gr  Miss Glam Medan   \n",
       "5768   YU CHUN Mei Cordyceps Lightening Night Cream 30g  Miss Glam Medan   \n",
       "5769           YU CHUN Mei Serum Whitening Essence 30ml  Miss Glam Medan   \n",
       "\n",
       "      Stok  Orig Daily Sales  Orig Max. Daily Sales  Lead Time  \\\n",
       "0     6.00              0.03                   1.00       5.00   \n",
       "1    13.00              0.25                   3.00       5.00   \n",
       "2     0.00              0.25                   2.00       5.00   \n",
       "3     8.00              0.24                   2.00       5.00   \n",
       "4     0.00              0.09                   1.00       5.00   \n",
       "...    ...               ...                    ...        ...   \n",
       "5765  0.00              0.03                   1.00       1.00   \n",
       "5766  2.00              0.02                   1.00       1.00   \n",
       "5767  4.00              0.03                   1.00       1.00   \n",
       "5768  0.00              0.06                   1.00       1.00   \n",
       "5769  5.00              0.08                   2.00       1.00   \n",
       "\n",
       "      Max. Lead Time  Min. Order  ...  Reorder point  Stock cover 30 days  \\\n",
       "0              28.00           1  ...             29                    1   \n",
       "1              28.00           1  ...             85                    8   \n",
       "2              28.00           1  ...             52                   11   \n",
       "3              12.00           3  ...             23                   12   \n",
       "4              12.00           3  ...             29                   19   \n",
       "...              ...         ...  ...            ...                  ...   \n",
       "5765            2.00           1  ...              3                    1   \n",
       "5766            2.00           3  ...              2                    1   \n",
       "5767            2.00           3  ...              2                    2   \n",
       "5768            2.00           3  ...              2                    2   \n",
       "5769            2.00           3  ...              2                    1   \n",
       "\n",
       "      current_stock_days_cover  is_open_po  initial_qty_po  emergency_po_qty  \\\n",
       "0                       200.00           0               0                 0   \n",
       "1                        52.00           0               0                 0   \n",
       "2                         0.00           1               0                 0   \n",
       "3                        20.22           1               4                 0   \n",
       "4                         0.00           1              13                 0   \n",
       "...                        ...         ...             ...               ...   \n",
       "5765                      0.00           1               1                 1   \n",
       "5766                     86.96           0               0                 0   \n",
       "5767                     72.46           0               0                 0   \n",
       "5768                      0.00           1               2                 1   \n",
       "5769                    217.39           0               0                 0   \n",
       "\n",
       "      updated_regular_po_qty  final_updated_regular_po_qty  emergency_po_cost  \\\n",
       "0                          0                             0               0.00   \n",
       "1                          0                             0               0.00   \n",
       "2                          0                             0               0.00   \n",
       "3                          4                             4               0.00   \n",
       "4                         13                            13               0.00   \n",
       "...                      ...                           ...                ...   \n",
       "5765                       0                             0           28428.00   \n",
       "5766                       0                             0               0.00   \n",
       "5767                       0                             0               0.00   \n",
       "5768                       1                             3           44289.00   \n",
       "5769                       0                             0               0.00   \n",
       "\n",
       "     final_updated_regular_po_cost  \n",
       "0                             0.00  \n",
       "1                             0.00  \n",
       "2                             0.00  \n",
       "3                        106492.00  \n",
       "4                        207662.00  \n",
       "...                            ...  \n",
       "5765                          0.00  \n",
       "5766                          0.00  \n",
       "5767                          0.00  \n",
       "5768                     132867.00  \n",
       "5769                          0.00  \n",
       "\n",
       "[5770 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 1: Import libraries and setup\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "from IPython.display import display\n",
    "import locale\n",
    "from locale import atof\n",
    "import numpy as np\n",
    "from openpyxl.styles import numbers\n",
    "\n",
    "\n",
    "\n",
    "# Apply the formatting to numeric columns in your final output\n",
    "def format_dataframe_display(df):\n",
    "    # Make a copy to avoid SettingWithCopyWarning\n",
    "    df_display = df.copy()\n",
    "    \n",
    "    # Apply formatting to numeric columns\n",
    "    for col in df_display.select_dtypes(include=['int64', 'float64']).columns:\n",
    "        df_display[col] = df_display[col].apply(\n",
    "            lambda x: format_id_number(x, 2) if pd.notna(x) else x\n",
    "        )\n",
    "    \n",
    "    return df_display\n",
    "\n",
    "# Configuration\n",
    "BASE_DIR = Path('/Users/andresuchitra/dev/missglam/autopo')\n",
    "SUPPLIER_PATH = BASE_DIR / 'data/supplier.csv'\n",
    "RAWPO_DIR = BASE_DIR / 'data/rawpo/csv'\n",
    "STORE_CONTRIBUTION_PATH = BASE_DIR / 'data/store_contribution.csv'\n",
    "OUTPUT_DIR = BASE_DIR / 'output/complete'\n",
    "OUTPUT_EXCEL_DIR = BASE_DIR / 'output/excel'\n",
    "OUTPUT_M2_DIR = BASE_DIR / 'output/m2'\n",
    "OUTPUT_EMERGENCY_DIR = BASE_DIR / 'output/emergency'\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(OUTPUT_EXCEL_DIR, exist_ok=True)\n",
    "os.makedirs(OUTPUT_M2_DIR, exist_ok=True)\n",
    "os.makedirs(OUTPUT_EMERGENCY_DIR, exist_ok=True)\n",
    "\n",
    "def load_store_contribution(store_contribution_path):\n",
    "    \"\"\"Load and prepare store contribution data.\"\"\"\n",
    "    store_contrib = pd.read_csv(store_contribution_path, header=None, \n",
    "                              names=['store', 'contribution_pct'])\n",
    "    # Convert store names to lowercase for case-insensitive matching\n",
    "    store_contrib['store_lower'] = store_contrib['store'].str.lower()\n",
    "    return store_contrib\n",
    "\n",
    "def get_contribution_pct(location, store_contrib):\n",
    "    \"\"\"Get contribution percentage for a given location.\"\"\"\n",
    "    location_lower = location.lower()\n",
    "\n",
    "    contrib_row = store_contrib[store_contrib['store_lower'] == location_lower]\n",
    "    if not contrib_row.empty:\n",
    "        return contrib_row['contribution_pct'].values[0]\n",
    "    print(f\"Warning: No contribution percentage found for {location}\")\n",
    "\n",
    "    return 100  # Default to 100% if not found\n",
    "\n",
    "def load_supplier_data(supplier_path):\n",
    "    \"\"\"Load and clean supplier data.\"\"\"\n",
    "    print(\"Loading supplier data...\")\n",
    "    df = pd.read_csv(supplier_path, sep=';', decimal=',').fillna('')\n",
    "    df['Nama Brand'] = df['Nama Brand'].str.strip()\n",
    "    return df\n",
    "\n",
    "def merge_with_suppliers(df_clean, supplier_df):\n",
    "    \"\"\"Merge PO data with supplier information.\"\"\"\n",
    "    print(\"Merging with suppliers...\")\n",
    "    \n",
    "    # Clean supplier data\n",
    "    supplier_clean = supplier_df.copy()\n",
    "    supplier_clean['Nama Brand'] = supplier_clean['Nama Brand'].astype(str).str.strip()\n",
    "    supplier_clean['Nama Store'] = supplier_clean['Nama Store'].astype(str).str.strip()\n",
    "    \n",
    "    # Deduplicate to prevent row explosion - Unique Brand+Store\n",
    "    supplier_clean = supplier_clean.drop_duplicates(subset=['Nama Brand', 'Nama Store'])\n",
    "    \n",
    "    # Ensure PO data has clean columns for merging\n",
    "    df_clean['Brand'] = df_clean['Brand'].astype(str).str.strip()\n",
    "    df_clean['Toko'] = df_clean['Toko'].astype(str).str.strip()\n",
    "    \n",
    "    # 1. Primary Merge: Match on Brand AND Store (Toko)\n",
    "    # This prioritizes the specific supplier for that store\n",
    "    merged_df = pd.merge(\n",
    "        df_clean,\n",
    "        supplier_clean,\n",
    "        left_on=['Brand', 'Toko'],\n",
    "        right_on=['Nama Brand', 'Nama Store'],\n",
    "        how='left',\n",
    "        suffixes=('_clean', '_supplier')\n",
    "    )\n",
    "    \n",
    "    # 2. Fallback: For unmatched rows, try to find ANY supplier for that Brand\n",
    "    # Identify rows where merge failed (Nama Brand is NaN)\n",
    "    unmatched_mask = merged_df['Nama Brand'].isna()\n",
    "    \n",
    "    if unmatched_mask.any():\n",
    "        print(f\"Found {unmatched_mask.sum()} rows without direct store match. Attempting fallback...\")\n",
    "        \n",
    "        # Get the unmatched rows and drop the empty supplier columns\n",
    "        unmatched_rows = merged_df[unmatched_mask].copy()\n",
    "        supplier_cols = [col for col in supplier_clean.columns if col in unmatched_rows.columns and col != 'Brand']\n",
    "        unmatched_rows = unmatched_rows.drop(columns=supplier_cols)\n",
    "        \n",
    "        # Create fallback supplier list (one per brand)\n",
    "        # We take the first one found for each brand\n",
    "        fallback_suppliers = supplier_clean.drop_duplicates(subset=['Nama Brand'])\n",
    "        \n",
    "        # Merge unmatched rows with fallback suppliers\n",
    "        matched_fallback = pd.merge(\n",
    "            unmatched_rows,\n",
    "            fallback_suppliers,\n",
    "            left_on='Brand',\n",
    "            right_on='Nama Brand',\n",
    "            how='left',\n",
    "            suffixes=('_clean', '_supplier')\n",
    "        )\n",
    "        \n",
    "        # Combine the initially matched rows with the fallback-matched rows\n",
    "        matched_initial = merged_df[~unmatched_mask]\n",
    "        merged_df = pd.concat([matched_initial, matched_fallback], ignore_index=True)\n",
    "    \n",
    "    # Clean up supplier columns\n",
    "    supplier_columns = [\n",
    "        'ID Supplier', 'Nama Supplier', 'ID Brand', 'ID Store', \n",
    "        'Nama Store', 'Hari Order', 'Min. Purchase', 'Trading Term',\n",
    "        'Promo Factor', 'Delay Factor'\n",
    "    ]\n",
    "    for col in supplier_columns:\n",
    "        if col in merged_df.columns:\n",
    "            merged_df[col] = merged_df[col].fillna('' if merged_df[col].dtype == 'object' else 0)\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "def calculate_inventory_metrics(df_clean):\n",
    "    \"\"\"\n",
    "    Calculate various inventory metrics including safety stock, reorder points, and PO quantities.\n",
    "    \n",
    "    Args:\n",
    "        df_clean (pd.DataFrame): Input dataframe with required columns\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Dataframe with added calculated columns\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Ensure we're working with a copy to avoid SettingWithCopyWarning\n",
    "    df = df_clean.copy()\n",
    "    \n",
    "    # Set display options\n",
    "    pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "    # Normalise stock column name\n",
    "    stock_col = 'Stok' if 'Stok' in df.columns else 'Stock'\n",
    "\n",
    "    # Force the columns we need into numeric form\n",
    "    numeric_cols = [\n",
    "        stock_col, 'Daily Sales', 'Max. Daily Sales', 'Lead Time',\n",
    "        'Max. Lead Time', 'Sedang PO', 'HPP', 'Lead Time Sedang PO'\n",
    "    ]\n",
    "    for col in numeric_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)\n",
    "    \n",
    "    try:\n",
    "        # 1. Safety stock calculation\n",
    "        df['Safety stock'] = (df['Max. Daily Sales'] * df['Max. Lead Time']) - (df['Daily Sales'] * df['Lead Time'])\n",
    "        df['Safety stock'] = df['Safety stock'].apply(lambda x: np.ceil(x)).fillna(0).astype(int)\n",
    "        \n",
    "        # 2. Reorder point calculation\n",
    "        df['Reorder point'] = np.ceil((df['Daily Sales'] * df['Lead Time']) + df['Safety stock']).fillna(0).astype(int)\n",
    "        \n",
    "        # 3. Stock cover for 30 days\n",
    "        df['Stock cover 30 days'] = (df['Daily Sales'] * 30).apply(lambda x: np.ceil(x)).fillna(0).astype(int)\n",
    "        \n",
    "        # 4. Current stock days cover\n",
    "        df['current_stock_days_cover'] = np.where(\n",
    "            df['Daily Sales'] > 0,\n",
    "            df[stock_col] / df['Daily Sales'],\n",
    "            0\n",
    "        )\n",
    "        \n",
    "        # 5. Is open PO flag\n",
    "        df['is_open_po'] = np.where(\n",
    "            (df['current_stock_days_cover'] < 30) & \n",
    "            (df['Stok'] <= df['Reorder point']), 1, 0\n",
    "        )\n",
    "        \n",
    "        # 6. Initial PO quantity\n",
    "        df['initial_qty_po'] = df['Stock cover 30 days'] - df[stock_col] - df.get('Sedang PO', 0)\n",
    "        df['initial_qty_po'] = (\n",
    "            pd.Series(\n",
    "                np.where(df['is_open_po'] == 1, df['initial_qty_po'], 0),\n",
    "                index=df.index\n",
    "            )\n",
    "            .clip(lower=0)\n",
    "            .astype(int)\n",
    "        )\n",
    "        \n",
    "        # 7. Emergency PO quantity\n",
    "        df['emergency_po_qty'] = np.where(\n",
    "            df.get('Sedang PO', 0) > 0,\n",
    "            np.maximum(0, (df['Lead Time Sedang PO'] - df['current_stock_days_cover']) * df['Daily Sales']),\n",
    "            np.ceil((df['Max. Lead Time'] - df['current_stock_days_cover']) * df['Daily Sales'])\n",
    "        )\n",
    "        \n",
    "        # Clean up emergency PO quantities\n",
    "        df['emergency_po_qty'] = (\n",
    "            df['emergency_po_qty']\n",
    "            .replace([np.inf, -np.inf], 0)\n",
    "            .fillna(0)\n",
    "            .clip(lower=0)\n",
    "            .astype(int)\n",
    "        )\n",
    "        \n",
    "        # 8. Updated regular PO quantity\n",
    "        df['updated_regular_po_qty'] = (df['initial_qty_po'] - df['emergency_po_qty']).clip(lower=0).astype(int)\n",
    "        \n",
    "        # 9. Final updated regular PO quantity (enforce minimum order)\n",
    "        df['final_updated_regular_po_qty'] = np.where(\n",
    "            (df['updated_regular_po_qty'] > 0) & \n",
    "            (df['updated_regular_po_qty'] < df['Min. Order']),\n",
    "            df['Min. Order'],\n",
    "            df['updated_regular_po_qty']\n",
    "        ).astype(int)\n",
    "        \n",
    "        # 10. Calculate costs if by multiplying with contribution percentage\n",
    "        df['emergency_po_cost'] = (df['emergency_po_qty'] * df['HPP']).round(2)\n",
    "        df['final_updated_regular_po_cost'] = (df['final_updated_regular_po_qty'] * df['HPP']).round(2)\n",
    "        \n",
    "        # Clean up any remaining NaN or infinite values\n",
    "        df = df.fillna(0)\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in calculate_inventory_metrics: {str(e)}\")\n",
    "        return df_clean\n",
    "\n",
    "def clean_po_data(df, location, contribution_pct=100, padang_sales=None):\n",
    "    \"\"\"Clean and prepare PO data with contribution calculations.\"\"\"\n",
    "    try:\n",
    "        # Create a copy to avoid modifying the original DataFrame\n",
    "        df = df.copy()\n",
    "\n",
    "        # Keep original column names but strip any extra whitespace\n",
    "        df.columns = df.columns.str.strip()\n",
    "\n",
    "        # Define required columns (using original case)\n",
    "        required_columns = [\n",
    "            'Brand', 'SKU', 'Nama', 'Toko', 'Stok',\n",
    "            'Daily Sales', 'Max. Daily Sales', 'Lead Time',\n",
    "            'Max. Lead Time', 'Min. Order', 'Sedang PO', 'HPP'\n",
    "        ]\n",
    "        \n",
    "        # Find actual column names in the DataFrame (case-sensitive)\n",
    "        available_columns = {col.strip(): col for col in df.columns}\n",
    "        columns_to_keep = []\n",
    "        \n",
    "        for col in required_columns:\n",
    "            if col in available_columns:\n",
    "                columns_to_keep.append(available_columns[col])\n",
    "            else:\n",
    "                print(f\"Warning: Column '{col}' not found in input data\")\n",
    "                # Add as empty column if it's required\n",
    "                if col in ['Brand', 'SKU', 'HPP']:  # These are critical\n",
    "                    df[col] = ''\n",
    "\n",
    "        # Select only the columns we need\n",
    "        df = df[[col for col in columns_to_keep if col in df.columns]]\n",
    "\n",
    "        # Check for missing required columns\n",
    "        missing_columns = [col for col in ['Brand', 'SKU', 'HPP'] if col not in df.columns]\n",
    "        if missing_columns:\n",
    "            raise ValueError(\n",
    "                f\"Missing required columns: {missing_columns}. \"\n",
    "                f\"Available columns: {df.columns.tolist()}\"\n",
    "            )\n",
    "\n",
    "        # Clean brand column\n",
    "        if 'Brand' in df.columns:\n",
    "            df['Brand'] = df['Brand'].astype(str).str.strip()\n",
    "\n",
    "        # Convert numeric columns with better error handling\n",
    "        numeric_columns = [\n",
    "            'Stok', 'Daily Sales', 'Max. Daily Sales', 'Lead Time',\n",
    "            'Max. Lead Time', 'Sedang PO', 'HPP'\n",
    "        ]\n",
    "\n",
    "        for col in numeric_columns:\n",
    "            if col in df.columns:\n",
    "                try:\n",
    "                    # First convert to string, clean, then to numeric\n",
    "                    df[col] = (\n",
    "                        df[col]\n",
    "                        .astype(str)\n",
    "                        .str.replace(r'[^\\d.,-]', '', regex=True)  # Remove non-numeric except .,-\n",
    "                        .str.replace(',', '.', regex=False)         # Convert commas to decimal points\n",
    "                        .replace('', '0')                           # Empty strings to '0'\n",
    "                        .astype(float)                              # Convert to float\n",
    "                        .fillna(0)                                  # Fill any remaining NaNs with 0\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(f\"Warning: Could not convert column '{col}' to numeric: {str(e)}\")\n",
    "                    df[col] = 0  # Set to 0 if conversion fails\n",
    "\n",
    "        # Add contribution percentage and calculate costs\n",
    "        contribution_pct = float(contribution_pct)\n",
    "        df['contribution_pct'] = contribution_pct\n",
    "        df['contribution_ratio'] = contribution_pct / 100\n",
    "\n",
    "        # Add default values for other required columns\n",
    "        if 'Lead Time Sedang PO' not in df.columns:\n",
    "            df['Lead Time Sedang PO'] = ''\n",
    "\n",
    "        location_upper = location.upper()\n",
    "        exempt_stores = {\"PADANG\", \"SOETA\", \"BALIKPAPAN\"}\n",
    "        needs_padang_override = (location_upper not in exempt_stores) or (contribution_pct < 100)\n",
    "\n",
    "        print(f\"Processing store: {location} - {contribution_pct}%\")\n",
    "\n",
    "        # Add 'Is in Padang' column\n",
    "        if padang_sales is not None:\n",
    "            padang_skus = set(padang_sales['SKU'].astype(str).unique())\n",
    "            df['Is in Padang'] = df['SKU'].astype(str).isin(padang_skus).astype(int)\n",
    "        else:\n",
    "            print(\"Warning: No Padang sales data provided. 'Is in Padang' will be set to 0 for all SKUs.\")\n",
    "            df['Is in Padang'] = 0\n",
    "\n",
    "        if not needs_padang_override:\n",
    "            # If no override needed, ensure we have the original sales columns\n",
    "            if 'Daily Sales' not in df.columns and 'Orig Daily Sales' in df.columns:\n",
    "                df['Daily Sales'] = df['Orig Daily Sales']\n",
    "            if 'Max. Daily Sales' not in df.columns and 'Orig Max. Daily Sales' in df.columns:\n",
    "                df['Max. Daily Sales'] = df['Orig Max. Daily Sales']\n",
    "            return df\n",
    "\n",
    "        if padang_sales is None:\n",
    "            raise ValueError(\n",
    "                \"Padang sales data is required for stores outside Padang/Soeta/Balikpapan \"\n",
    "                \"or any store with contribution < 100%.\"\n",
    "            )\n",
    "\n",
    "        # Process Padang sales data - keep original column names\n",
    "        padang_df = padang_sales.copy()\n",
    "        padang_df.columns = padang_df.columns.str.strip()  # Only strip whitespace\n",
    "        \n",
    "        # Ensure required columns exist in padang_df\n",
    "        required_padang_cols = ['SKU', 'Daily Sales', 'Max. Daily Sales']\n",
    "        missing_padang_cols = [col for col in required_padang_cols if col not in padang_df.columns]\n",
    "        \n",
    "        if missing_padang_cols:\n",
    "            raise ValueError(\n",
    "                f\"Padang sales data is missing required columns: {missing_padang_cols}. \"\n",
    "                f\"Available columns: {padang_df.columns.tolist()}\"\n",
    "            )\n",
    "\n",
    "        # Save original sales columns if they exist\n",
    "        if 'Daily Sales' in df.columns and 'Orig Daily Sales' not in df.columns:\n",
    "            df = df.rename(columns={'Daily Sales': 'Orig Daily Sales'})\n",
    "        if 'Max. Daily Sales' in df.columns and 'Orig Max. Daily Sales' not in df.columns:\n",
    "            df = df.rename(columns={'Max. Daily Sales': 'Orig Max. Daily Sales'})\n",
    "\n",
    "        print(\"Overriding with Padang sales data...\")\n",
    "        contribution_ratio = contribution_pct / 100\n",
    "\n",
    "        # Merge with Padang's sales data using original column names\n",
    "        df = df.merge(\n",
    "            padang_df[['SKU', 'Daily Sales', 'Max. Daily Sales']].rename(columns={\n",
    "                'Daily Sales': 'Padang Daily Sales',\n",
    "                'Max. Daily Sales': 'Padang Max Daily Sales'\n",
    "            }),\n",
    "            on='SKU',\n",
    "            how='left'\n",
    "        )\n",
    "\n",
    "        # Calculate adjusted sales based on contribution and 'Is in Padang' flag\n",
    "        if 'Padang Daily Sales' in df.columns and 'Orig Daily Sales' in df.columns:\n",
    "            df['Daily Sales'] = np.where(\n",
    "                df['Is in Padang'] == 1,\n",
    "                df['Padang Daily Sales'] * contribution_ratio,\n",
    "                df['Orig Daily Sales']\n",
    "            )\n",
    "            \n",
    "        if 'Padang Max Daily Sales' in df.columns and 'Orig Max. Daily Sales' in df.columns:\n",
    "            df['Max. Daily Sales'] = np.where(\n",
    "                df['Is in Padang'] == 1,\n",
    "                df['Padang Max Daily Sales'] * contribution_ratio,\n",
    "                df['Orig Max. Daily Sales']\n",
    "            )\n",
    "\n",
    "        # Drop intermediate columns\n",
    "        columns_to_drop = [\n",
    "            'Padang Daily Sales', 'Padang Max Daily Sales'\n",
    "        ]\n",
    "        df = df.drop(columns=[col for col in columns_to_drop if col in df.columns], errors='ignore')\n",
    "\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in clean_po_data: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "        # Return empty DataFrame with required columns if there's an error\n",
    "        desired_columns = [\n",
    "            'Brand', 'SKU', 'Nama', 'HPP', 'Toko', 'Stok', \n",
    "            'Daily Sales', 'Max. Daily Sales', 'Lead Time', \n",
    "            'Max. Lead Time', 'Sedang PO', 'contribution_pct',\n",
    "            'emergency_po_cost', 'final_updated_regular_po_cost',\n",
    "            'Is in Padang'  # Added new column\n",
    "        ]\n",
    "        return pd.DataFrame(columns=desired_columns)\n",
    "\n",
    "def get_store_name_from_filename(filename):\n",
    "    \"\"\"Extract store name from filename, handling different patterns.\"\"\"\n",
    "    # Remove file extension and split by spaces\n",
    "    name_parts = Path(filename).stem.split()\n",
    "    \n",
    "    # Handle cases like \"002 Miss Glam Pekanbaru.csv\" -> \"Pekanbaru\"\n",
    "    # or \"01 Miss Glam Padang.csv\" -> \"Padang\"\n",
    "    if len(name_parts) >= 3 and name_parts[1].lower() == 'miss' and name_parts[2].lower() == 'glam':\n",
    "        return ' '.join(name_parts[3:]).strip().upper()\n",
    "    elif len(name_parts) >= 2 and name_parts[0].lower() == 'miss' and name_parts[1].lower() == 'glam':\n",
    "        return ' '.join(name_parts[2:]).strip().upper()\n",
    "    # Fallback: take everything after the first space\n",
    "    elif ' ' in filename:\n",
    "        return ' '.join(name_parts[1:]).strip().upper()\n",
    "    return name_parts[0].upper()\n",
    "\n",
    "def read_excel_file(file_path):\n",
    "    \"\"\"\n",
    "    Read an Excel file from RAWPO_EXCEL_DIR with robust error handling.\n",
    "    Handles Excel files with 'NAN', 'INF', and other error values gracefully.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the Excel file\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame if successful, None otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read Excel with dtype=str and na_filter=False to prevent pandas/openpyxl \n",
    "        # from trying to interpret 'NAN'/'INF' strings as special values\n",
    "        # We will handle type conversion later in clean_po_data\n",
    "        df = pd.read_excel(\n",
    "            file_path, \n",
    "            engine='openpyxl',\n",
    "            dtype=str,           # Read all columns as strings initially\n",
    "            na_filter=False      # Don't convert strings like 'NAN' to NaN\n",
    "        )\n",
    "        \n",
    "        # Check if DataFrame is empty\n",
    "        if not df.empty:\n",
    "            print(f\"âœ“ Successfully read {file_path.name} with openpyxl\")\n",
    "            return df\n",
    "        else:\n",
    "            print(f\"âš  Warning: {file_path.name} is empty\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Error reading {file_path.name} with openpyxl: {str(e)}\")\n",
    "        \n",
    "        # Try with xlrd engine as fallback for older Excel formats (.xls)\n",
    "        try:\n",
    "            df = pd.read_excel(\n",
    "                file_path, \n",
    "                engine='xlrd',\n",
    "                dtype=str,\n",
    "                na_filter=False\n",
    "            )\n",
    "            if not df.empty:\n",
    "                print(f\"âœ“ Successfully read {file_path.name} with xlrd (fallback)\")\n",
    "                return df\n",
    "            else:\n",
    "                print(f\"âš  Warning: {file_path.name} is empty\")\n",
    "                return None\n",
    "                \n",
    "        except Exception as e2:\n",
    "            print(f\"âœ— Error reading {file_path.name} with xlrd: {str(e2)}\")\n",
    "    \n",
    "    # If we get here, all attempts failed\n",
    "    print(f\"âœ— Failed to read {file_path.name} with any known method\")\n",
    "    return None\n",
    "\n",
    "def read_csv_file(file_path):\n",
    "    # List of (separator, encoding) combinations to try\n",
    "    formats_to_try = [\n",
    "        (',', 'utf-8'),      # Standard CSV with comma\n",
    "        (';', 'utf-8'),      # Semicolon with UTF-8\n",
    "        (',', 'latin1'),     # Comma with Latin1\n",
    "        (';', 'latin1'),     # Semicolon with Latin1\n",
    "        (',', 'cp1252'),     # Windows-1252 encoding\n",
    "        (';', 'cp1252')\n",
    "    ]\n",
    "    \n",
    "    for sep, enc in formats_to_try:\n",
    "        try:\n",
    "            df = pd.read_csv(\n",
    "                file_path,\n",
    "                sep=sep,\n",
    "                decimal=',',\n",
    "                thousands='.',\n",
    "                encoding=enc,\n",
    "                engine='python'  # More consistent behavior with Python engine\n",
    "            )\n",
    "            # If we get here, the file was read successfully\n",
    "            if not df.empty:\n",
    "                return df\n",
    "        except (UnicodeDecodeError, pd.errors.ParserError, pd.errors.EmptyDataError) as e:\n",
    "            continue  # Try next format\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error reading {file_path} with sep='{sep}', encoding='{enc}': {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # If we get here, all attempts failed\n",
    "    print(f\"Failed to read {file_path} with any known format\")\n",
    "    return None\n",
    "\n",
    "def process_po_file(file_path, supplier_df, store_contrib, df_padang):\n",
    "    \"\"\"Process a single PO file and return merged data and summary.\"\"\"\n",
    "    print(f\"\\nProcessing {file_path.name}...\")\n",
    "    \n",
    "    try:\n",
    "        # Extract location from filename using the new function\n",
    "        location = get_store_name_from_filename(file_path.name)\n",
    "        print(f\"  - Extracted location: {location}\")  # Debug print\n",
    "        \n",
    "        contribution_pct = get_contribution_pct(location, store_contrib)\n",
    "        \n",
    "        # Read the CSV with error handling\n",
    "        try:\n",
    "            # Try reading with different encodings if needed\n",
    "            df = read_csv_file(file_path)\n",
    "            # df = read_excel_file(file_path)\n",
    "            \n",
    "            # Check if DataFrame is empty\n",
    "            if df.empty:\n",
    "                raise ValueError(\"File is empty\")\n",
    "                \n",
    "            # Clean the data\n",
    "            df_clean = clean_po_data(df,location, contribution_pct, df_padang)\n",
    "            \n",
    "            # Skip if cleaning failed\n",
    "            if df_clean.empty:\n",
    "                raise ValueError(\"Data cleaning failed\")\n",
    "            \n",
    "            # Merge with suppliers\n",
    "            merged_df = merge_with_suppliers(df_clean, supplier_df)\n",
    "\n",
    "            # calculate metrics PO\n",
    "            merged_df = calculate_inventory_metrics(merged_df)\n",
    "            \n",
    "            # Generate summary\n",
    "            padang_count = (merged_df['Nama Store'] == 'Miss Glam Padang').sum()\n",
    "            other_supplier_count = ((merged_df['Nama Store'] != 'Miss Glam Padang') & \n",
    "                                  (merged_df['Nama Store'] != '')).sum()\n",
    "            \n",
    "            summary = {\n",
    "                'file': file_path.name,\n",
    "                'location': location,\n",
    "                'contribution_pct': contribution_pct,\n",
    "                'total_rows': len(merged_df),\n",
    "                'padang_suppliers': int(padang_count),\n",
    "                'other_suppliers': int(other_supplier_count),\n",
    "                'no_supplier': int((merged_df['Nama Store'] == '').sum()),\n",
    "                'status': 'Success'\n",
    "            }\n",
    "            \n",
    "            return merged_df, summary\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Error processing file data: {str(e)}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error processing {file_path.name}: {str(e)}\"\n",
    "        print(f\"  - {error_msg}\")\n",
    "        return None, {\n",
    "            'file': file_path.name,\n",
    "            'location': location if 'location' in locals() else 'Unknown',\n",
    "            'contribution_pct': contribution_pct if 'contribution_pct' in locals() else 0,\n",
    "            'total_rows': 0,\n",
    "            'padang_suppliers': 0,\n",
    "            'other_suppliers': 0,\n",
    "            'no_supplier': 0,\n",
    "            'status': f\"Error: {str(e)[:100]}\"  # Truncate long error messages\n",
    "        }\n",
    "\n",
    "def load_padang_data(padang_path):\n",
    "    print(\"Parsing Padang data...\")\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(padang_path, sep=';', decimal=',', thousands='.')\n",
    "\n",
    "        print(f\"Padang data loaded successfully..\")\n",
    "        display(df.head(10))\n",
    "\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error loading Padang data: {str(e)}\")\n",
    "\n",
    "def format_number_for_csv(x):\n",
    "    \"\"\"Format numbers for CSV output with Indonesian locale (comma as decimal, dot as thousand)\"\"\"\n",
    "    if pd.isna(x) or x == '':\n",
    "        return x\n",
    "    try:\n",
    "        if isinstance(x, (int, float)):\n",
    "            if x == int(x):  # Whole number\n",
    "                return f\"{int(x):,d}\".replace(\",\", \".\")\n",
    "            else:  # Decimal number\n",
    "                return f\"{x:,.2f}\".replace(\",\", \"X\").replace(\".\", \",\").replace(\"X\", \".\")\n",
    "        return x\n",
    "    except:\n",
    "        return x\n",
    "\n",
    "def save_to_csv(df, filename):\n",
    "    df_output = df.copy()\n",
    "\n",
    "    # Ensure SKU stays textual\n",
    "    if 'SKU' in df_output.columns:\n",
    "        df_output['SKU'] = df_output['SKU'].apply(lambda x: f'=\"{x}\"')\n",
    "\n",
    "    # Only touch numeric columns\n",
    "    numeric_cols = df_output.select_dtypes(include=['number']).columns\n",
    "    for col in numeric_cols:\n",
    "        df_output[col] = df_output[col].apply(format_number_for_csv)\n",
    "\n",
    "    output_path = OUTPUT_DIR / filename\n",
    "    df_output.to_csv(output_path, index=False, sep=';', decimal=',', encoding='utf-8-sig')\n",
    "    print(f\"File saved to {output_path}\")\n",
    "\n",
    "def save_to_excel(df, filename, sheet_name=\"PO\"):\n",
    "    df_output = df.copy()\n",
    "    df_output['SKU'] = df_output['SKU'].apply(lambda x: f'=\"{x}\"')\n",
    "\n",
    "    output_path = OUTPUT_EXCEL_DIR / filename\n",
    "    with pd.ExcelWriter(output_path, engine=\"openpyxl\") as writer:\n",
    "        df_output.to_excel(writer, index=False, sheet_name=sheet_name)\n",
    "        ws = writer.sheets[sheet_name]\n",
    "        sku_col_idx = df_output.columns.get_loc(\"SKU\") + 1\n",
    "        for cell in ws.iter_cols(min_col=sku_col_idx, max_col=sku_col_idx,\n",
    "                                 min_row=2, max_row=ws.max_row):\n",
    "            for c in cell:\n",
    "                c.number_format = numbers.FORMAT_TEXT\n",
    "    print(f\"File Excel saved to {output_path}\")\n",
    "\n",
    "def save_to_m2_format(df, filename, is_excel: bool = False):\n",
    "    # Filter to only include rows with regular PO qty > 0\n",
    "    df_filtered = df[df['final_updated_regular_po_qty'] > 0].copy()\n",
    "    df_output = df_filtered[['Toko', 'SKU', 'HPP', 'final_updated_regular_po_qty']]\n",
    "    \n",
    "    # Ensure SKU stays textual\n",
    "    if 'SKU' in df_output.columns:\n",
    "        df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n",
    "    \n",
    "    output_path = OUTPUT_M2_DIR / filename\n",
    "    if is_excel:\n",
    "        df_output.to_excel(output_path, index=False)\n",
    "    else:\n",
    "        df_output.to_csv(output_path, index=False, sep=';', decimal=',', encoding='utf-8-sig')\n",
    "    print(f\"File M2 format saved to {output_path}\")\n",
    "\n",
    "def save_to_emergency_po_format(df, filename, is_excel: bool = False):\n",
    "    # Filter to only include rows with emergency PO qty > 0\n",
    "    df_filtered = df[df['emergency_po_qty'] > 0].copy()\n",
    "    df_output = df_filtered[['Brand', 'SKU', 'Nama', 'Toko' , 'HPP', 'emergency_po_qty', 'emergency_po_cost']]\n",
    "    \n",
    "    # Ensure SKU stays textual\n",
    "    if 'SKU' in df_output.columns:\n",
    "        df_output['SKU'] = df_output['SKU'].apply(lambda x: f'{x}')\n",
    "    \n",
    "    output_path = OUTPUT_EMERGENCY_DIR / filename\n",
    "    if is_excel:\n",
    "        df_output.to_excel(output_path, index=False)\n",
    "    else:\n",
    "        df_output.to_csv(output_path, index=False, sep=';', decimal=',', encoding='utf-8-sig')\n",
    "    print(f\"File emergency po saved to {output_path}\")\n",
    "\n",
    "def main():\n",
    "    # Load data\n",
    "    supplier_df = load_supplier_data(SUPPLIER_PATH)\n",
    "    store_contrib = load_store_contribution(STORE_CONTRIBUTION_PATH)\n",
    "    all_summaries = []\n",
    "\n",
    "    # get padang df first\n",
    "    df_padang = load_padang_data('data/rawpo/csv/1. Miss glam Padang.csv')\n",
    "\n",
    "    # Process each PO file\n",
    "    for file_path in sorted(RAWPO_DIR.glob('*.csv')):\n",
    "        try:\n",
    "            merged_df, summary = process_po_file(file_path, supplier_df, store_contrib, df_padang)\n",
    "            \n",
    "            # Save results\n",
    "            output_path = OUTPUT_DIR / f'with_suppliers_{file_path.name}'\n",
    "            m2_output_path = OUTPUT_DIR / f'm2_{file_path.name}'\n",
    "            emergency_output_path = file_path.name\n",
    "\n",
    "            save_to_csv(merged_df, output_path.name)\n",
    "            save_to_m2_format(merged_df, m2_output_path.name)\n",
    "            save_to_emergency_po_format(merged_df, emergency_output_path)\n",
    "\n",
    "\n",
    "            summary['output_path'] = str(output_path)\n",
    "            \n",
    "            # Print progress\n",
    "            print(f\"  - Location: {summary['location']}\")\n",
    "            print(f\"  - Contribution: {summary['contribution_pct']}%\")\n",
    "            print(f\"  - Rows processed: {summary['total_rows']}\")\n",
    "            print(f\"  - 'Miss Glam Padang' suppliers: {summary['padang_suppliers']} rows\")\n",
    "            print(f\"  - Other suppliers: {summary['other_suppliers']} rows\")\n",
    "            print(f\"  - No supplier data: {summary['no_supplier']} rows\")\n",
    "            print(f\"  - Saved to: {output_path}\")\n",
    "            \n",
    "            all_summaries.append(summary)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path.name}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Display final summary\n",
    "    if all_summaries:\n",
    "        print(\"\\nProcessing complete! Summary:\")\n",
    "        summary_df = pd.DataFrame(all_summaries)\n",
    "        display(summary_df)\n",
    "        \n",
    "        # Show sample of last processed file\n",
    "        print(\"\\nSample of the last processed file:\")\n",
    "        display(merged_df)\n",
    "    else:\n",
    "        print(\"\\nNo files were processed successfully.\")\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
